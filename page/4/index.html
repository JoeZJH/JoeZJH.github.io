<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="En/中">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="本博客主要用于记录个人学习笔记">
<meta name="keywords" content="Python, Computer, ML, Linux, Ubuntu, NLP, Git, DL,">
<meta property="og:type" content="website">
<meta property="og:title" content="Jiahong的个人博客">
<meta property="og:url" content="https://JoeZJH.github.io/page/4/index.html">
<meta property="og:site_name" content="Jiahong的个人博客">
<meta property="og:description" content="本博客主要用于记录个人学习笔记">
<meta property="og:locale" content="En/中">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jiahong的个人博客">
<meta name="twitter:description" content="本博客主要用于记录个人学习笔记">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://JoeZJH.github.io/page/4/">





  <title>Jiahong的个人博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="En/中">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jiahong的个人博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">凡事预则立，不预则废</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/ComputationalAdvertising/CA——多任务学习总结.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/ComputationalAdvertising/CA——多任务学习总结.html" itemprop="url">CA——多任务学习总结</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>多任务学习，multi-task learning</em></p>
<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<h3 id="多任务学习的结构"><a href="#多任务学习的结构" class="headerlink" title="多任务学习的结构"></a>多任务学习的结构</h3><h4 id="ESMM及扩展"><a href="#ESMM及扩展" class="headerlink" title="ESMM及扩展"></a>ESMM及扩展</h4><h4 id="MMoE及相关变体"><a href="#MMoE及相关变体" class="headerlink" title="MMoE及相关变体"></a>MMoE及相关变体</h4><h3 id="多任务学习的损失函数权重设置"><a href="#多任务学习的损失函数权重设置" class="headerlink" title="多任务学习的损失函数权重设置"></a>多任务学习的损失函数权重设置</h3><h4 id="基于人工经验的人工优化"><a href="#基于人工经验的人工优化" class="headerlink" title="基于人工经验的人工优化"></a>基于人工经验的人工优化</h4><ul>
<li>一般思想是对齐损失函数均值，并按照业务偏好有所倾斜，如果愿意花时间尝试，往往能拿到不错的结果</li>
</ul>
<h4 id="基于贝叶斯推论的权重优化"><a href="#基于贝叶斯推论的权重优化" class="headerlink" title="基于贝叶斯推论的权重优化"></a>基于贝叶斯推论的权重优化</h4><ul>
<li>基于不确定性的权重设置方法（Uncertainty Weighting）</li>
<li>基本公式<br>$$<br>L(\mathbf{W}, \sigma_1, \sigma_2,…,\sigma_K) = \sum_{k=1}^K \frac{1}{2\sigma^2}L(\mathbf{W}) + \log \sigma^2<br>$$<ul>
<li>上述公式可通过推导得出<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf" target="_blank" rel="noopener">Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</a><ul>
<li>可以推导，无论是回归问题还是分类问题（也可以是分类和回归问题的混合），都可以按照上面的方法设置损失函数（分类问题证明中会使用到一个近似值，不是严格推导）</li>
<li>推导是在假设</li>
</ul>
</li>
<li>\(\sigma\)是可学习的参数，初始设置固定值，然后使用梯度更新学习即可</li>
<li>使用简单，实际使用时效果也确实不错，建议人工调参也可以在先使用该方案拿到权重量级后继续</li>
</ul>
</li>
</ul>
<h4 id="帕累托最优权重优化"><a href="#帕累托最优权重优化" class="headerlink" title="帕累托最优权重优化"></a>帕累托最优权重优化</h4><ul>
<li><p>原始论文：<a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/432aca3a1e345e339f35a30c8f65edce-Paper.pdf" target="_blank" rel="noopener">Multi-Task Learning as Multi-Objective Optimization</a></p>
<img src="/Notes/ComputationalAdvertising/CA——多任务学习总结/pareto-optimazation-for-MTL.png"></li>
<li><p>内积的含义：向量A到向量B的投影长度与向量B长度的乘积</p>
</li>
<li><p>Algorithm1展示的是，对于两个任务的情况，图示展示了二维向量的情况，可以通过判断向量之间的关系确定求解\(\alpha\)的方式</p>
<ul>
<li>Algorithm2中的FrankWolfeSlover算法则是对Algorithm1的多任务扩展</li>
</ul>
</li>
<li><p>其他参考，阿里巴巴多任务学习帕累托最优论文：<a href="https://yongfeng.me/attach/lin-recsys2019.pdf" target="_blank" rel="noopener">A Pareto-Efficient Algorithm for Multiple Objective Optimization in E-Commerce Recommendation</a></p>
</li>
</ul>
<h3 id="损失函数优化"><a href="#损失函数优化" class="headerlink" title="损失函数优化"></a>损失函数优化</h3><h4 id="损失函数归一化"><a href="#损失函数归一化" class="headerlink" title="损失函数归一化"></a>损失函数归一化</h4><p><em>可用于解决由于不同任务损失函数量级差异带来的问题</em></p>
<h5 id="普通版本"><a href="#普通版本" class="headerlink" title="普通版本"></a>普通版本</h5><p>$$<br>L_{norm} = \frac{L_k(\mathbf{W})}{L_0(\mathbf{W_0})}<br>$$</p>
<ul>
<li>使用各个任务自己的第一次输出的损失函数作为基础损失函数，其中\(L_0(\mathbf{W_0}\)为第一次计算loss的到的损失函数</li>
</ul>
<h5 id="滑动平均版本"><a href="#滑动平均版本" class="headerlink" title="滑动平均版本"></a>滑动平均版本</h5><p>$$<br>L_{base} = \alpha L_{base} + (1-\alpha) L_k \\<br>L_{norm} = \frac{L_k(\mathbf{W})}{L_{base}} \\<br>$$</p>
<ul>
<li>使用滑动平均来记录基础损失函数，该方案可进一步减少由于初始化损失误差过大带来的问题</li>
</ul>
<h4 id="梯度归一化（GradNorm）"><a href="#梯度归一化（GradNorm）" class="headerlink" title="梯度归一化（GradNorm）"></a>梯度归一化（GradNorm）</h4><ul>
<li>原始论文：<a href="https://proceedings.mlr.press/v80/chen18a/chen18a.pdf" target="_blank" rel="noopener">GradNorm: Gradient Normalization for Adaptive Loss Balancing in Deep Multitask Networks</a><img src="/Notes/ComputationalAdvertising/CA——多任务学习总结/grad-norm-definition-for-MTL.png">
<img src="/Notes/ComputationalAdvertising/CA——多任务学习总结/grad-norm-for-MTL.png"></li>
<li>核心思想是对各任务的损失函数进行加权(\(w_i\))求和得到更新共享参数的损失函数</li>
<li>“GradNorm”这个名字的由来是因为权重\(w_i\)是与梯度2范数的期望等有关的？</li>
<li>公式中\(w_i\)是各个任务损失函数对共享参数损失函数的权重，该权重初始值为1，在训练过程中逐步更新，每一步最后都保持该权重加和为\(T\)（\(T\)为任务数量，即保证权重均值为1）</li>
<li>问题：文中没有明确各个任务各自的参数如何更新，猜测各自更新即可</li>
</ul>
<h3 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h3><ul>
<li>一般情况下，根据业务特点，尽量使用类似于ESMM结构</li>
<li>权重设置尝试次序：<ul>
<li>对损失函数进行归一化（梯度归一化好像效果一般？）</li>
<li>权重设置时，先使用不确定性权重（Uncertainty Weighting）跑一版，得到基线</li>
<li>在Uncertainty Weighting的基础上，人工可以根据业务需要微调，可以偏向于需要的任务</li>
<li>帕累托最优实现复杂，且不一定有收益<ul>
<li>复杂体现在：需要在每个batch上重新求解最优化问题，得到当前的loss权重（用上一个batch的梯度求解这一个batch的最优权重）</li>
</ul>
</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/ComputationalAdvertising/CA——Google-Ad-Click-Prediction.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/ComputationalAdvertising/CA——Google-Ad-Click-Prediction.html" itemprop="url">CA——Google-Ad-Click-Prediction</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


<ul>
<li>参考文献：<a href="https://dl.acm.org/doi/pdf/10.1145/2487575.2488200?download=true" target="_blank" rel="noopener">Google KDD 2013，Ad Click Prediction: a View from the Trenches</a>(引用量500+)</li>
<li>介绍了截止到2013年之前的点击率预估常用算法，FTRL是Google三年的结晶（2010-2013）</li>
<li><strong>在线学习</strong>优化算法的发展历程：SGD-&gt;TG-&gt;FOBOS-&gt;RDA-&gt;FTRL-Proximal</li>
</ul>
<h3 id="核心贡献"><a href="#核心贡献" class="headerlink" title="核心贡献"></a>核心贡献</h3><ul>
<li>基于传统的逻辑回归算法(Regularized Logistic Regression，正则化的逻辑回归)在点击率预估时的不足，提出一种<strong>在线逻辑回归</strong>算法，FTRL(Follow The Regularized Leader)</li>
<li>per-coordinate learning rate</li>
</ul>
<h3 id="一些模型的比较和介绍"><a href="#一些模型的比较和介绍" class="headerlink" title="一些模型的比较和介绍"></a>一些模型的比较和介绍</h3><ul>
<li>传统逻辑回归算法中使用OGD(Online Gradient Descent)是非常高效的，使用很小的计算资源就能得到较好的精确度.</li>
<li>但是OGD在生成<strong>稀疏</strong>模型方面表现不好(OGD + L1)</li>
<li>其他在稀疏性方面表现良好的方法有FOBOS, 截断梯度（Truncated Gradient）和 RDA（Regularized Dual Averaging)<ul>
<li>RDA在精确度和稀疏性方面做tradeoff， 效果好于FOBOS</li>
</ul>
</li>
<li>FTRL-Proximal号称可以同时获得RDA的稀疏性和OGD的精确度</li>
<li>RDA模型是微软提出的一种在线优化算法，与OGD完全不同，能得到更加稀疏的模型，但是精确度不如OGD</li>
</ul>
<h3 id="FTRL-Proximal-Learning-Online-Learning-And-Sparsity"><a href="#FTRL-Proximal-Learning-Online-Learning-And-Sparsity" class="headerlink" title="FTRL-Proximal Learning (Online Learning And Sparsity)"></a>FTRL-Proximal Learning (Online Learning And Sparsity)</h3><ul>
<li>也是通过L1正则化控制模型的稀疏度</li>
</ul>
<h4 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h4><h5 id="FTL-Follow-The-Leader-的介绍"><a href="#FTL-Follow-The-Leader-的介绍" class="headerlink" title="FTL(Follow The Leader)的介绍"></a>FTL(Follow The Leader)的介绍</h5><h5 id="OGD的更新方式"><a href="#OGD的更新方式" class="headerlink" title="OGD的更新方式"></a>OGD的更新方式</h5><ul>
<li>更新规则：<br>$$<br>\begin{align}<br>\mathbf{w}_{t+1} &amp;= \mathbf{w}_t-\eta_t\mathbf{g}_t<br>\end{align}<br>$$</li>
</ul>
<h5 id="FTLR-Follow-The-Regularized-Leader"><a href="#FTLR-Follow-The-Regularized-Leader" class="headerlink" title="FTLR(Follow The Regularized Leader)"></a>FTLR(Follow The Regularized Leader)</h5><p><em>加上正则项的FTL</em></p>
<ul>
<li>更新规则：<br>$$<br>\begin{align}<br>\mathbf{w}_{t+1} &amp;= \arg\min_{\mathbf{w}}\left ( \mathbf{g}_{1:t}\cdot \mathbf{w} + \frac{1}{2}\sum_{s=1}^t \sigma_s || \mathbf{w} - \mathbf{w}_s||_2^2 + \lambda_1||\mathbf{w}||_1 \right ) \\<br>\mathbf{g}_{1:t} &amp;= \sum_{i=1}^t\mathbf{g}_i<br>\end{align}<br>$$<ul>
<li>第一项是对损失函数梯度的贡献的一个估计</li>
<li>第二项是控制参数\(\mathbf{w}\)在每次迭代中变化不要太大</li>
<li>第三项是L1正则化，用于使模型变得稀疏（除了L1正则化项以外，也可以再加上L2正则化）</li>
<li>去掉正则化项就是FTL（Follow The Leader）</li>
<li>\(\sigma_s\)是学习速率</li>
<li>这个学习速率可以用Per-Coordinate Learning Rate:<br>$$<br>\begin{align}<br>\eta_{t, i} &amp;= \frac{\alpha}{\beta + \sqrt{\sum_{s=1}^t g_{s,i}^2}} \\<br>\mathbf{g}_s &amp;= \nabla l_s(\mathbf{w})<br>\end{align}<br>$$</li>
</ul>
</li>
</ul>
<h3 id="Per-Coordinate-Learning-Rates"><a href="#Per-Coordinate-Learning-Rates" class="headerlink" title="Per-Coordinate Learning Rates"></a>Per-Coordinate Learning Rates</h3><ul>
<li>对参数的每一维度分开训练，每个维度有自己的学习率</li>
<li>某个特征出现的次数越多，说明当前该特征对应的参数值越可信，学习率就应该越小</li>
<li>考虑了数据在每个特征上的分布不均匀性<ul>
<li>参数某个维度上的样本数越少，这些样本就会得到越大的利用(具体表现就是该特征的学习率会比较大)</li>
</ul>
</li>
</ul>
<h3 id="一个思考"><a href="#一个思考" class="headerlink" title="一个思考"></a>一个思考</h3><ul>
<li>问题：为什么机器学习中的学习率都是越来越小？</li>
<li>答案：因为刚开始训练时，参数的值不太可信（也就是说最终参数与当前参数的置信度比较低），所以更新时应该更新的步骤大一些，让当前的参数变化大一些，训练到后来，随着参数的值越来越可信（当前参数的置信度比较高），更新的步骤就应该小一些，让当前的变化小一些</li>
</ul>
<h3 id="一些工程上的Trick"><a href="#一些工程上的Trick" class="headerlink" title="一些工程上的Trick"></a>一些工程上的Trick</h3><h4 id="Saving-Memory-at-Massive-Scale"><a href="#Saving-Memory-at-Massive-Scale" class="headerlink" title="Saving Memory at Massive Scale"></a>Saving Memory at Massive Scale</h4><h5 id="Probabilistic-Feature-Inclusion"><a href="#Probabilistic-Feature-Inclusion" class="headerlink" title="Probabilistic Feature Inclusion"></a>Probabilistic Feature Inclusion</h5><ul>
<li>在高维数据中，大量的特征是出现频率非常低的(rare)，半数的唯一特征甚至只出现一次</li>
<li>统计这些特征的代价是非常昂贵的，有些特征可能永远不会被实际使用(这里如何理解昂贵？也就是说训练了也没用？)</li>
<li>额外的读写数据是昂贵的，如果能丢弃一部分出现评论特别低的特征(比如出现频率低于k次)</li>
<li>实现稀疏可以使用L1正则化，也可以使用Probabilistic Feature Inclusion</li>
<li>关于Probabilistic Feature Inclusion的做法<ul>
<li>当一个特征第一次出现时，以一定的概率接受这个新特征</li>
<li>效果作用于数据预处理阶段，但是可以在在线执行中设置</li>
</ul>
</li>
</ul>
<h6 id="Possion-Inclusion"><a href="#Possion-Inclusion" class="headerlink" title="Possion Inclusion"></a>Possion Inclusion</h6><ul>
<li>对于新的特征，以概率p添加入模型</li>
<li>对于已经存在模型中的特征，正常更新其系数</li>
</ul>
<h6 id="Bloom-Filter-Inclusion"><a href="#Bloom-Filter-Inclusion" class="headerlink" title="Bloom Filter Inclusion"></a>Bloom Filter Inclusion</h6><ul>
<li>用布隆过滤器仅仅保留出现次数在n次以上的特征</li>
</ul>
<img src="/Notes/ComputationalAdvertising/CA——Google-Ad-Click-Prediction/inclusion_methods.png">

<h5 id="Encoding-Values-with-Fewer-Bits"><a href="#Encoding-Values-with-Fewer-Bits" class="headerlink" title="Encoding Values with Fewer Bits"></a>Encoding Values with Fewer Bits</h5><ul>
<li>常用的OGD使用32或者64位浮点数编码来存储模型的系数</li>
<li>Google提出可以使用16位浮点数来存储系数，同时加上一些策略</li>
<li>实验结果：将64位的浮点值换为为系数存储节省了75%的RAM内存空间(这还用实验？直接计算就得到了啊)</li>
</ul>
<h5 id="Training-Many-Similar-Models"><a href="#Training-Many-Similar-Models" class="headerlink" title="Training Many Similar Models"></a>Training Many Similar Models</h5><ul>
<li>同时训练多个模型是超参数选择常用的方法</li>
<li>将可以共享的东西共享</li>
<li>在节省内存的同时，还可以节约网络带宽(存储一份Per-coordinate学习率，节省内存和带宽等)，CPU(用同一个hash表检索特征，节省CPU)和硬盘空间</li>
</ul>
<h5 id="A-Single-Value-Structure"><a href="#A-Single-Value-Structure" class="headerlink" title="A Single Value Structure"></a>A Single Value Structure</h5><ul>
<li>有时候我们希望评估大量的模型在只有少量的特征组(groups of features)添加或者删除时的变化</li>
<li>对于每一维度(coordinate),仅仅存储一个系数值而不是多个(正常应该为每个模型存储一个)</li>
<li>存储该维度对应特征组的模型共享该系数</li>
<li>对每个特征，训练时每个模型都会计算自己的值，然后所有模型的取平均作为所有包含该维度特征模型的共享</li>
</ul>
<h5 id="Computing-Learning-Rates-with-Counts"><a href="#Computing-Learning-Rates-with-Counts" class="headerlink" title="Computing Learning Rates with Counts"></a>Computing Learning Rates with Counts</h5><ul>
<li>对于每个特征来说，<strong>梯度和</strong>以及<strong>梯度平方和</strong>是必须计算的</li>
<li>梯度的计算必须准确，但是计算学习率却是可以粗糙计算的</li>
<li>仅仅统计样本出现次数(Counts)就能大概计算学习率</li>
</ul>
<h6 id="推导"><a href="#推导" class="headerlink" title="推导"></a>推导</h6><ul>
<li>假设包含一个给定特征的所有事件(events)具有有相同的概率(一般来说，这个近似是不可能的，但是在这个目标里面是可行的)<ul>
<li>如何理解这个假设的意义呢？<strong>对于具有某个特征的所有样本，其取值为(正负例)是的概率是相等的，正例(click)概率都为\(p\)</strong></li>
</ul>
</li>
<li>进一步假设模型已经精确地学习到了概率</li>
<li>如果有分别有\(P，N\)个正负样本(events),则有\(p=\frac{P}{N+P}\)</li>
<li>则有对于逻辑回归(\(p(1-p)\))来说，正例的梯度为\(p-1\),负例的梯度为\(p\)<br>$$<br>\begin{align}<br>\sum g_{t,i}^2 &amp;= \sum_{positive \ events}(1-p_t)^2 + \sum_{negative \ events}p_t^2 \\<br>&amp;\approx P(1-\frac{P}{N+P})^2 + N(\frac{P}{N+P})^2 \\<br>&amp;= \frac{PN}{N+P}<br>\end{align}<br>$$</li>
<li>也就是说，为了近似计算\(\sum g_{t,i}^2\)，我们仅需要记录\(P，N\)即可</li>
</ul>
<h5 id="Subsampling-Traning-Data"><a href="#Subsampling-Traning-Data" class="headerlink" title="Subsampling Traning Data"></a>Subsampling Traning Data</h5><ul>
<li>典型的CTRs是远远低于50%，数据偏差很大，正例(点击)的样本很稀疏</li>
<li>在模型训练中正例样本相对而言更有价值</li>
<li>使用下采样：很大程度上降低数据量，同时保证对精度最小程度的影响</li>
</ul>
<h6 id="采样方法："><a href="#采样方法：" class="headerlink" title="采样方法："></a>采样方法：</h6><ul>
<li>保留所有至少被点击过一次的请求(Query，也就是样本)</li>
<li>以一定比例\(r\in(0, 1]\)采样没有被点击过的请求</li>
<li>因为包含通用的特征(Feature Phase)计算，所以这种方法是合理的，但是需要纠偏(直接用采样后的样本训练会造成预测偏差)</li>
<li>加入一个重要性权重\(w_t\)<ul>
<li>\(w_t = 1\) for clicked queries</li>
<li>\(w_t = \frac{1}{r}\) for queries with no clicks</li>
<li>本质上可以理解为这里是将采样时造成的负例比例偏差补齐</li>
</ul>
</li>
</ul>
<h3 id="模型性能评估"><a href="#模型性能评估" class="headerlink" title="模型性能评估"></a>模型性能评估</h3><h4 id="Progressive-Validation"><a href="#Progressive-Validation" class="headerlink" title="Progressive Validation"></a>Progressive Validation</h4><ul>
<li>Progressive验证又称为在线损失(online loss)</li>
<li>与交叉验证(cross-validation)或留出法(hold out)验证是不同的</li>
<li>在服务查询中，在线损失能很好的代表我们的精度，因为在训练模型前，它仅仅在最新数据上评估其性能(因为这准确的模拟了当模型进行服务查询时发生了什么)</li>
<li>由于用了100%的数据作为训练和测试，在线损失比留出法验证有更好的统计数据</li>
<li>绝对指标往往会带来误导<ul>
<li>即使预测是完美的，对数损失和其他指标的差异也依赖着问题的困难程度</li>
<li>不同的国家，不同请求的点击率不同(同为对数损失的最佳实践，50%的点击率会好于2%的点击率)</li>
</ul>
</li>
<li>所以使用相对变化，看指标相对于base line改变了多少</li>
<li>从经验来看，相对指标在整个时间段内都很稳定</li>
<li>相同的指标计算应该对应在完全相同的数据(比如不同时段的损失比较是没有意义的)</li>
</ul>
<h3 id="置信度评估-Confidence-Estimates"><a href="#置信度评估-Confidence-Estimates" class="headerlink" title="置信度评估(Confidence Estimates)"></a>置信度评估(Confidence Estimates)</h3><ul>
<li>对很多应用来说，除了评估广告的CTR，还要量化预测的期望精确度(the expected accuracy of the prediction)</li>
</ul>
<h3 id="校正预测-Calibrating-Predictions"><a href="#校正预测-Calibrating-Predictions" class="headerlink" title="校正预测(Calibrating Predictions)"></a>校正预测(Calibrating Predictions)</h3><ul>
<li>系统偏差(Systematic Bias)指平均预测CTR(Average Predicted CTR)和观测CTR(Observed CTR)的差异</li>
<li>造成系统偏差的原因包括：<ul>
<li>不精确的模型假设</li>
<li>学习算法的缺陷</li>
<li>在训练或者服务(预测)时不可用的隐藏特征</li>
</ul>
</li>
<li>解决方案：<ul>
<li>添加一个校正层将预测CTRs与观测CTR做匹配(match predicted CTRSs to observed click-through rates)</li>
<li>暂时不能提供有效的保证，保证校正影响的有效</li>
<li>校正的本质是找到(拟合)一个函数映射\(g\),使得模型输出值与真实概率值一一对应</li>
<li>逻辑回归中的sigmoid函数可以看做是一个校正预测的函数吗？</li>
</ul>
</li>
<li>更多参考<ul>
<li><a href="https://blog.csdn.net/fzcoolbaby/article/details/99174601?utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">风险模型 - 概率校准</a></li>
<li><a href="https://www.cnblogs.com/lc1217/p/7069000.html" target="_blank" rel="noopener">机器学习：概率校准</a>, 文中有代码示例</li>
<li><a href="https://blog.csdn.net/fjsd155/article/details/84382838?utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">概率校准 Probability Calibration</a></li>
</ul>
</li>
</ul>
<h4 id="一些说明"><a href="#一些说明" class="headerlink" title="一些说明"></a>一些说明</h4><p><em>参考博客：<a href="https://blog.csdn.net/fzcoolbaby/article/details/99174601?utm_source=distribute.pc_relevant.none-task" target="_blank" rel="noopener">https://blog.csdn.net/fzcoolbaby/article/details/99174601?utm_source=distribute.pc_relevant.none-task</a></em></p>
<ul>
<li>概率模型的搭建过程中，由于抽样与正则化等原因，导致模型的输出概率值明显偏离真实概率值<ul>
<li>[待更新：为什么抽样和正则化会影响模型的输出概率发生变化？]</li>
</ul>
</li>
<li>此时的模型输出概率值仅仅有排序的意义，其绝对值没有意义(定序值，而非定距数值)</li>
<li>校正预测的过程就是把模型输出概率值的校正成真实的概率的过程，使得校正后的概率有绝对值意义</li>
</ul>
<h3 id="自动特征管理-Automated-Feature-Management"><a href="#自动特征管理-Automated-Feature-Management" class="headerlink" title="自动特征管理(Automated Feature Management)"></a>自动特征管理(Automated Feature Management)</h3><ul>
<li>将特征空间描绘成上下文和语义信号，每个信号都可以被翻译成一个在学习时有真实值的特征集合</li>
<li>[待更新]</li>
</ul>
<h3 id="一些不成功的实验记录-Unsuccessful-Experiments"><a href="#一些不成功的实验记录-Unsuccessful-Experiments" class="headerlink" title="一些不成功的实验记录(Unsuccessful Experiments)"></a>一些不成功的实验记录(Unsuccessful Experiments)</h3><p><em>本节记录google的一些失败的尝试方向(有些可能会让人很惊讶)，这些方向模型没有明显收益</em></p>
<h4 id="Aggressive-Feature-Hashing"><a href="#Aggressive-Feature-Hashing" class="headerlink" title="Aggressive Feature Hashing"></a>Aggressive Feature Hashing</h4><p><em>关于特征哈希(Feature Hashing)的相关知识可参考<a href="/Notes/ComputationalAdvertising/CA%E2%80%94%E2%80%94Feature-Hashing.html">Feature-Hashing</a></em></p>
<ul>
<li><a href="http://alex.smola.org/papers/2009/Weinbergeretal09.pdf" target="_blank" rel="noopener">Feature Hashing for Large Scale Multitask Learning</a>论文指出，Feature Hashing方法效果显著<ul>
<li>报告显示使用特征hashing技巧，可以能将学习一个垃圾邮件过滤模型的特征空间映射成包含\(2^24\)个特征的特征空间(疑问：这里的特征原来不止\(2^24\)个吗？)</li>
</ul>
</li>
<li>但是实验证明，使用 Feature Hashing 方法并不能提升我们的方法，所以建议保留 interpretable(non-hashed)的特征向量</li>
</ul>
<h4 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h4><ul>
<li>Google用网格搜索的方法测试了从0.1到0.5的Dropout特征丢弃概率</li>
<li>所有情况均没有带来任何收益(包括精度指标和泛化能力)，还往往给模型带来损害(detriment)</li>
<li>Google给出的一个解释是：Dropout在图像领域取得较好收益的原因是因为图像领域的数据特征分布与计算广告领域不同<ul>
<li>图像领域：稠密特征，此时Dropout把结果(effect)从强相关的特征中分离开来，从而得到泛化效果更好的分类器</li>
<li>计算广告：稀疏特征，且有噪音</li>
</ul>
</li>
</ul>
<h4 id="Feature-Bagging"><a href="#Feature-Bagging" class="headerlink" title="Feature Bagging"></a>Feature Bagging</h4><ul>
<li>对特征进行overlapping采样(注意，样本Bagging和特征Bagging不同)，然后训练多个独立的模型，最后取平均值</li>
<li>实验证明模型的的AucLoss降低了0.1%-0.6%</li>
</ul>
<h4 id="Feature-Vector-Normalization"><a href="#Feature-Vector-Normalization" class="headerlink" title="Feature Vector Normalization"></a>Feature Vector Normalization</h4><ul>
<li>\(\mathbf{x} = \frac{\mathbf{x}}{||\mathbf{x}||}\)</li>
<li>开始有一点精度上的收益，但是后面也出现了一定程度的detriment</li>
<li>Google的解释是可能是由于per-coordinate learning rates和正则化的影响</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/Hexo/Hexo——Next主题搜索窗口无法弹出.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/Hexo/Hexo——Next主题搜索窗口无法弹出.html" itemprop="url">Hexo——Next主题搜索窗口无法弹出</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>参考博客： <a href="https://www.sqlsec.com/2017/12/hexosearch.html" target="_blank" rel="noopener">https://www.sqlsec.com/2017/12/hexosearch.html</a></li>
</ul>
<h3 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h3><ul>
<li>有时候会遇到在Mac上Next主题窗口无法弹出的问题</li>
<li>问题分为两类<ul>
<li>一类为找不到 <code>search.xml</code> 文件：加载 <code>search.xml</code> 时错误为404</li>
<li>另一类为文章中有特殊字符：加载 <code>search.xml</code> 检查时错误为304</li>
</ul>
</li>
</ul>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><h4 id="404类"><a href="#404类" class="headerlink" title="404类"></a>404类</h4><ul>
<li><p>修改最外层配置文件<code>./_config.yml</code>,添加以下语句(实测这一步非必须)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">search:</span><br><span class="line">  path: search.xml</span><br><span class="line">  field: post</span><br><span class="line">  format: html</span><br><span class="line">  limit: 10000</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装搜索插件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="304类"><a href="#304类" class="headerlink" title="304类"></a>304类</h4><ul>
<li>304状态说明是加载文件存在，但是无法正常解析文件</li>
<li>直接用浏览器访问 <code>search.xml</code> 文件链接，然后查看文件解析异常出现在哪个地方，然后删除特殊字符即可<ul>
<li>个人理解，从哪个文件不能搜索，特殊字符就出现在哪个文件中</li>
<li>说明：目前还没遇到过这种情况，后面遇到会再补充</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/ComputationalAdvertising/CA——Feature-Hashing.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/ComputationalAdvertising/CA——Feature-Hashing.html" itemprop="url">CA——Feature-Hashing</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <ul>
<li>参考文献: <a href="http://alex.smola.org/papers/2009/Weinbergeretal09.pdf" target="_blank" rel="noopener">Feature Hashing for Large Scale Multitask Learning</a></li>
<li>特征哈希(Feature Hashing)常用于数据特征降维，同时尽量保留原始特征的表达能力<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<h3 id="论文贡献"><a href="#论文贡献" class="headerlink" title="论文贡献"></a>论文贡献</h3></li>
<li>给出了一种高维数据降维方法，特征哈希(Feature Hashing)</li>
<li>严格证明了特征哈希的可用性</li>
</ul>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul>
<li>一种构造组合特征的方法是笛卡尔乘积</li>
<li>计算广告领域往往有数十亿的高维特征</li>
<li>一种表达方式是使用词表法，对每个特征从词表里面进行查询<ul>
<li>缺陷一：拓展问题，每次拓展词表时难度较大(难以进行模型升级，因为特征维度在变化)</li>
<li>缺陷二：无法处理词表中不存在的特征(Unknown特征)</li>
</ul>
</li>
<li>一般的降维方法容易带来特征表达能力的损失</li>
</ul>
<h3 id="特征哈希"><a href="#特征哈希" class="headerlink" title="特征哈希"></a>特征哈希</h3><ul>
<li><p>哈希函数定义(参考自博客：<a href="https://blog.csdn.net/qjf42/article/details/82387559" target="_blank" rel="noopener">https://blog.csdn.net/qjf42/article/details/82387559</a>)</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">def feature_hashing(features, m):</span><br><span class="line">	&quot;&quot;&quot;</span><br><span class="line">	Args:</span><br><span class="line">		features: 输入特征序列，可以是数字，字符串(本质还是数字)</span><br><span class="line">		m: 输出的特征维度，通常是2**26(vw),2**20(scikit-learn)</span><br><span class="line">	Returns:</span><br><span class="line">		m维的（稀疏）向量</span><br><span class="line">	&quot;&quot;&quot;</span><br><span class="line">	# 这里的x一般是稀疏表示的（如：scipy.sparse.csr_matrix），这里是为了方便说明</span><br><span class="line">    x = np.zeros(m)</span><br><span class="line">    for feature in features:</span><br><span class="line">    	# hash_func_1保证散列尽量平均且散列速度快</span><br><span class="line">        idx = hash_func_1(feature) % m </span><br><span class="line">        # 这里在原始论文中</span><br><span class="line">        sign = hash_func_2(feature) % 2</span><br><span class="line">        if sign == 1:</span><br><span class="line">            x[idx] += 1</span><br><span class="line">        else:</span><br><span class="line">            x[idx] -= 1</span><br><span class="line">    return x</span><br></pre></td></tr></table></figure>

<ul>
<li>输出特征维度一般为\(m = 2^24\)等，是一个认为给定的数字</li>
</ul>
</li>
<li><p>与词表法比较：</p>
<ul>
<li>解决了模型升级时的特征拓展问题(增加新特征时，特征的维度不会变化)</li>
<li>解决了Unknown特征问题(个人理解：因为hash函数不管是什么特征，都可以一视同仁)</li>
<li>无需查表，节省了查表的时间(个人理解：其实查表时一般实现方式也是用哈希表构建索引，所以这里不能算是优势)</li>
<li>完成了降维(这里是把字典法里面对邮件或者文档的id也算作一个特征，这个特征one hot表示一下将会造成数据维度变得非常大？但是id算做特征有什么意义吗？)</li>
</ul>
</li>
</ul>
<h3 id="一些说明"><a href="#一些说明" class="headerlink" title="一些说明"></a>一些说明</h3><ul>
<li>冲突总会发生，也就是说不同一个特征总有一定的概率被映射到同一个维度(即两个不同特征的<code>idx</code>值可能相等)上</li>
<li>Paper中的垃圾邮件过滤模型实验证明：冲突造成的损失漏召率在\(m=2^22\)时影响约为1%，接近不做hash时的效果(特征维度在不做hash约为\(2^{25}\))且在\(m=2^{18}\)时为1.12%，也只升高了一点点</li>
<li>另外：无论如何，总有特殊情况，比如重要的特征如用户的性别特征“男”和“女”二者可能被映射到同一个维度上<ul>
<li>这里编码时是男:<code>(1, 0)</code>, 女<code>(0, 1)</code>这样的，所以如果二者映射到同一个维度上，那么这两个特征丢失了原本的表达能力</li>
<li>真实环境中如果遇到这些问题将会很难调试，如果找到了相关的问题，可以通过修改映射函数的输入参数字符串等方式来错开两个特征</li>
</ul>
</li>
<li>特征哈希本身可以类比于机器学习中的核技巧,所以特征哈希也称为哈希技巧</li>
</ul>
<h3 id="一些理解"><a href="#一些理解" class="headerlink" title="一些理解"></a>一些理解</h3><h4 id="知乎用户"><a href="#知乎用户" class="headerlink" title="知乎用户"></a>知乎用户</h4><ul>
<li>参考<a href="https://www.zhihu.com/people/ainika-peng" target="_blank" rel="noopener">Ainika Peng</a>的博客：<a href="https://www.zhihu.com/question/264165760/answer/279676705" target="_blank" rel="noopener">https://www.zhihu.com/question/264165760/answer/279676705</a></li>
<li>一般而言这类技术是为了解决两个问题：<ul>
<li>一是<strong>将categorical的特征编码为模型可理解的格式</strong>, 这是个基础问题。One-Hot Serializing就可以达到这个效果，例如将训练样本中出现过的的每个deviceid按顺序递增编号（比如deviceid@xxx:1 -&gt; feature@10000:1）。<ul>
<li>缺点1：这个映射表需要传递给引擎端，在prediction的时候照着再查一遍，数据量大且数据结构设计不好的时候很费时间；</li>
<li>缺点2：有些频次很低的特征置信度不高，单独出现对模型无益（甚至over-fitting）。这时候可以使用按频次截断技术进行降维。比如微软在deep crossing中提到的特征工程方法：只保留曝光最多的10k个campaign id编码为0-9999，其余的id全部编码为10000，但辅以poCTR等连续特征作为辅助。事实上这是一种手工的Hashing方法。</li>
</ul>
</li>
<li>二是<strong>尽可能在保留有效信息的基础上降低训练和预测过程的时间复杂度</strong></li>
</ul>
</li>
<li>自动Hashing方法的好处是：<ul>
<li>只要训练和预测时使用的hashing方法一致，对同一个特征的编码结果即一致，因此引擎预测或提供数据dump的时候无需查找编码表。所以其最大优点在于数据一致性和速度提升，这在极大规模特征和在线学习中至关重要。</li>
</ul>
</li>
<li>我们说的Hashing算法一般而言均特意设计为低碰撞率。<ul>
<li>因此一般hashing算法本身不会大幅降低特征维度，自然也不会大幅损失特征信息。真正可能存在问题的是hashing之后的降维过程。</li>
<li>一个非常常见的陷阱是string哈希到int64后取模m，试图将特征压缩至m维one-hot空间。在这种情况下，对于不知情的随机hashing过程，不同特征的碰撞率为1/m。举个例子，对于“性别”特征，将male哈希为一个int64，female哈希为另一个int64，很难发生碰撞；但如果你试图使用mod2将其压缩，如果你的算法哈希出的这两个int64奇偶性相同，则会导致特征失效。在你有很多feature需要哈希而又不清楚hashing算法细节的情况下，这在概率意义上是很容易发生的。<ul>
<li>这里的mod2是极端举例，其实m的取值小于原始维度的情况下都有一定概率造成冲突</li>
</ul>
</li>
</ul>
</li>
<li>因此我们会更倾向于所谓的embedding算法<ul>
<li>例如将70万维的userid通过weight embedding到32维的连续值特征上（不同于传统hashing的低维离散值特征）。这意味着训练过程更加复杂（有更多的weight需要optimize）；但对于预测过程，其特征性能十分良好且时间复杂度得以降低。同时，由于连续值特征空间的表达能力大幅高于离散值特征空间，整个模型的表达能力并不会明显下降，也基本不会发生离散hashing的碰撞问题。</li>
<li>当然，如果是<strong>FM这类倾向于接受离散值的模型，手工serializing+精心设计的hashing是较好的选择</strong>。</li>
</ul>
</li>
<li>优点：<ul>
<li>训练和预测的时间复杂度大幅降低；</li>
<li>数据的一致性强，不存在同一个特征今天编码成这个、明天编码成那个的情况，便于跟踪单特征效果；</li>
<li>对new feature可以直接编码并加入训练，无需等待编码表统计并反馈；</li>
<li>降低feature space大小，（精心设计可以）降低over-fitting的几率。</li>
</ul>
</li>
<li>缺点<ul>
<li>在不清楚hashing function细节的情况下，容易导致特征碰撞失效，且难以排查；</li>
<li>难以通过hashing出的特征反推源特征；</li>
<li>embedding会降低模型的可解释性。</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/Others/General——各种包的管理总结.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/Others/General——各种包的管理总结.html" itemprop="url">General——各种包的管理总结</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<h3 id="编程语言相关"><a href="#编程语言相关" class="headerlink" title="编程语言相关"></a>编程语言相关</h3><ul>
<li>参考链接: <a href="https://help.github.com/en/github/managing-packages-with-github-packages/about-github-packages#supported-clients-and-formats" target="_blank" rel="noopener">https://help.github.com/en/github/managing-packages-with-github-packages/about-github-packages#supported-clients-and-formats</a></li>
</ul>
<table>
<thead>
<tr>
<th align="left">Package client</th>
<th align="left">Language</th>
<th align="left">Package format</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody><tr>
<td align="left">npm</td>
<td align="left">JavaScript</td>
<td align="left">package.json</td>
<td align="left">Node package manager</td>
</tr>
<tr>
<td align="left">gem</td>
<td align="left">Ruby</td>
<td align="left">Gemfile</td>
<td align="left">RubyGems package manager</td>
</tr>
<tr>
<td align="left">mvn</td>
<td align="left">Java</td>
<td align="left">pom.xml</td>
<td align="left">Apache Maven project management and comprehension tool</td>
</tr>
<tr>
<td align="left">gradle</td>
<td align="left">Java</td>
<td align="left">build.gradle or build.gradle.kts</td>
<td align="left">Gradle build automation tool for Java</td>
</tr>
<tr>
<td align="left">docker</td>
<td align="left">N/A</td>
<td align="left">Dockerfile</td>
<td align="left">Docker container management platform</td>
</tr>
<tr>
<td align="left">nuget</td>
<td align="left">.NET</td>
<td align="left">nupkg</td>
<td align="left">NuGet package management for .NET</td>
</tr>
<tr>
<td align="left">pip</td>
<td align="left">Python</td>
<td align="left">requirements.txt</td>
<td align="left">use <code>pip install -r requirements.txt</code></td>
</tr>
</tbody></table>
<hr>
<h3 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h3><ul>
<li>参考链接: <a href="https://www.iteye.com/blog/justcoding-1937171" target="_blank" rel="noopener">https://www.iteye.com/blog/justcoding-1937171</a></li>
</ul>
<table>
<thead>
<tr>
<th align="left">软件管理方式</th>
<th align="left">线下安装命令</th>
<th align="left">线上安装命令</th>
<th align="left">distribution 操作系统</th>
</tr>
</thead>
<tbody><tr>
<td align="left">RPM</td>
<td align="left">rpm, rpmbuild</td>
<td align="left">yum</td>
<td align="left">Red Hat/Fedora</td>
</tr>
<tr>
<td align="left">DPKG</td>
<td align="left">dpkg</td>
<td align="left">apt, apt-get</td>
<td align="left">Debian/Ubuntu</td>
</tr>
</tbody></table>
<hr>
<h3 id="rpm和dpkg常用命令总结"><a href="#rpm和dpkg常用命令总结" class="headerlink" title="rpm和dpkg常用命令总结"></a>rpm和dpkg常用命令总结</h3><ul>
<li>参考链接: <a href="http://cha.homeip.net/blog/archives/2005/08/rpm_vs_dpkg.html" target="_blank" rel="noopener">http://cha.homeip.net/blog/archives/2005/08/rpm_vs_dpkg.html</a></li>
</ul>
<table>
<thead>
<tr>
<th align="left">操作描述</th>
<th align="center">rpm</th>
<th align="center">dpkg</th>
</tr>
</thead>
<tbody><tr>
<td align="left">安装指定套件</td>
<td align="center">rpm -i pkgfile.rpm</td>
<td align="center">dpkg -i pkgfile.deb</td>
</tr>
<tr>
<td align="left">显示所有已安装的套件名称</td>
<td align="center">rpm -qa</td>
<td align="center">dpkg -l</td>
</tr>
<tr>
<td align="left">显示套件包含的所有档案</td>
<td align="center">rpm -ql [softwarename]</td>
<td align="center">dpkg -L [softwarename]</td>
</tr>
<tr>
<td align="left">显示特定档案所属套件名称</td>
<td align="center">rpm -qf [/path/to/file]</td>
<td align="center">dpkg -S [/path/to/file]</td>
</tr>
<tr>
<td align="left">显示制定套件是否安装</td>
<td align="center">rpm -q [softwarename]</td>
<td align="center">dpkg -l [softwarename], -s或-p显示详细咨询, -l只列出简洁咨询</td>
</tr>
<tr>
<td align="left">移除指定套件</td>
<td align="center">rpm -e [softwarename]</td>
<td align="center">dpkg -r softwarename, -r 留下套件设定, -P完全移除</td>
</tr>
</tbody></table>
<hr>
<h3 id="apt和yum常用命令总结"><a href="#apt和yum常用命令总结" class="headerlink" title="apt和yum常用命令总结"></a>apt和yum常用命令总结</h3><ul>
<li>参考博客: <a href="https://cnblogs.com/lanbosm/p/9130211.html" target="_blank" rel="noopener">https://cnblogs.com/lanbosm/p/9130211.html</a></li>
</ul>
<table>
<thead>
<tr>
<th align="left">操作描述</th>
<th align="center">yum</th>
<th align="center">apt</th>
</tr>
</thead>
<tbody><tr>
<td align="left">软件源配置文件路径</td>
<td align="center">/etc/yum.conf</td>
<td align="center">/etc/apt/sources.list</td>
</tr>
<tr>
<td align="left">安装软件包</td>
<td align="center">yum install [package]</td>
<td align="center">apt-get install [package]</td>
</tr>
<tr>
<td align="left">删除软件包</td>
<td align="center">yum uninstall [package]</td>
<td align="center">apt-get remove [package]</td>
</tr>
<tr>
<td align="left">删除有依赖关系的软件包和配置文件</td>
<td align="center">yum uninstall [package]</td>
<td align="center">apt-get autoremove [package] –purge</td>
</tr>
<tr>
<td align="left">查看安装包信息</td>
<td align="center">yum info [package]</td>
<td align="center">apt-cache show [package]</td>
</tr>
<tr>
<td align="left">更新软件包列表</td>
<td align="center">yum update</td>
<td align="center">apt-get update</td>
</tr>
<tr>
<td align="left">清空缓存</td>
<td align="center">yum clean</td>
<td align="center">apt-get clean</td>
</tr>
<tr>
<td align="left">搜索包名</td>
<td align="center">yum</td>
<td align="center">apt-cahce search</td>
</tr>
</tbody></table>
<hr>
<h3 id="一些特殊命令"><a href="#一些特殊命令" class="headerlink" title="一些特殊命令"></a>一些特殊命令</h3><h4 id="apt"><a href="#apt" class="headerlink" title="apt"></a>apt</h4><ul>
<li><p>列出所有可用包名</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-cache pkgnames</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过描述列出包名</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-cache search [keys]</span><br></pre></td></tr></table></figure>
</li>
<li><p>指定包的版本号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install [package]=[version]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="yum"><a href="#yum" class="headerlink" title="yum"></a>yum</h4><ul>
<li><p>搜索包的可用版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum --showduplicates list [package] | expand</span><br></pre></td></tr></table></figure>

<ul>
<li><code>expand</code>命令用于将文件的制表符<code>tab</code>转换成空格符<code>space</code><ul>
<li>默认一个<code>tab</code>对应8个<code>space</code></li>
<li>若不指定文件名(或者文件名为<code>-</code>), 则<code>expand</code>会从标准输入读取数据</li>
</ul>
</li>
<li><code>unexpand</code>命令与expand相反</li>
</ul>
</li>
<li><p>安装时指定包的版本号</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install [package]-[version]</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="yum和apt安装的常用参数"><a href="#yum和apt安装的常用参数" class="headerlink" title="yum和apt安装的常用参数"></a>yum和apt安装的常用参数</h4><ul>
<li><code>-y</code>: 指定在询问是否安装时均选择<code>yes</code></li>
<li><code>-q</code>: <code>quiet</code>,安装途中不打印log信息</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/Others/General——各种压缩方式总结.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/Others/General——各种压缩方式总结.html" itemprop="url">General——各种压缩方式总结</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<h3 id="tar-gz"><a href="#tar-gz" class="headerlink" title=".tar.gz"></a>.tar.gz</h3><h3 id="tar-bz2"><a href="#tar-bz2" class="headerlink" title=".tar.bz2"></a>.tar.bz2</h3><h3 id="tar-xz"><a href="#tar-xz" class="headerlink" title=".tar.xz"></a>.tar.xz</h3><h3 id="tgz"><a href="#tgz" class="headerlink" title=".tgz"></a>.tgz</h3>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/Linux/Centos——clamav安装与杀毒.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/Linux/Centos——clamav安装与杀毒.html" itemprop="url">Centos——clamav安装与杀毒</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>clam是一款Linux上免费的杀毒软件</em></p>
<hr>
<h3 id="安装与配置"><a href="#安装与配置" class="headerlink" title="安装与配置"></a>安装与配置</h3><h4 id="命令行安装"><a href="#命令行安装" class="headerlink" title="命令行安装"></a>命令行安装</h4><p><em>命令行安装clamav会自动创建clamav用户和clamav组</em></p>
<ul>
<li><p>Centos</p>
</li>
<li><p>在Centos7亲测*</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install –y clamav clamav-update</span><br></pre></td></tr></table></figure>
</li>
<li><p>ubuntu</p>
</li>
<li><p>在Ubuntu16.04上亲测*</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install clamav</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h4 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a>源码安装</h4><p><em>如果因为某些原因无法从命令行安装,可以尝试用源码安装,此时需要首先手动创建相关组和用户</em></p>
<h5 id="安装前的配置"><a href="#安装前的配置" class="headerlink" title="安装前的配置"></a>安装前的配置</h5><ul>
<li><p>创建clamav组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">groupadd clamav</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建用户并添加到clamav组</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">useradd -g clamav clamav</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="源码下载和安装"><a href="#源码下载和安装" class="headerlink" title="源码下载和安装"></a>源码下载和安装</h5><ul>
<li><p>下载</p>
<ul>
<li>下载链接: <a href="http://www.clamav.net/downloads" target="_blank" rel="noopener">http://www.clamav.net/downloads</a>, 因为版本可能会有更新,这里我们直接给出网站下载地址,可以随时查看版本信息</li>
<li>找到软件包下载链接后,使用wget下载即可,比如<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.clamav.net/downloads/production/clamav-0.102.0.tar.gz</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>安装</p>
<ul>
<li><p>解压</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xf clamav-0.102.0.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>切换目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd clamav-0.102.0</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装依赖</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum/apt install gcc openssl openssl-devel</span><br></pre></td></tr></table></figure>

</li>
</ul>
</li>
</ul>
<hr>
<h3 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h3><h4 id="升级病毒库"><a href="#升级病毒库" class="headerlink" title="升级病毒库"></a>升级病毒库</h4><ul>
<li><p>升级命令</p>
<ul>
<li><p>命令行安装后更新命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">freshclam</span><br></pre></td></tr></table></figure>
</li>
<li><p>源码安装后更新命令, 也可以建立软连接后直接使用上面的命令行启动</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/clamav/bin/freshclam</span><br></pre></td></tr></table></figure>
</li>
<li><p>建立链接指令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ln -s [source path] [target path]</span><br></pre></td></tr></table></figure>


</li>
</ul>
</li>
</ul>
<h4 id="查找病毒文件"><a href="#查找病毒文件" class="headerlink" title="查找病毒文件"></a>查找病毒文件</h4><ul>
<li><p>常用命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup clamscan / -r --infected -l clamscan.log &gt; clamscan.out &amp;</span><br></pre></td></tr></table></figure>

<ul>
<li><code>-r</code> 指明递归查杀</li>
<li><code>--infected</code> 表示仅仅输出被感染的部分文件, 否则没有被感染的文件会输出<code>文件名: OK</code>这样无用的信息</li>
<li><code>-l</code> 指明日志文件路径</li>
<li><code>/</code> 是查找的目标目录,如果是整个机器查找则使用<code>/</code></li>
<li>由于查杀病毒需要很长时间,所以建议使用后台进程进行, 如果是远程, 建议使用<code>nohup</code></li>
<li>由于输出非常多,所以一般我们使用<code>clamscan.out</code>和<code>clamscan.log</code>分别存储输出和日志</li>
</ul>
</li>
<li><p>列出被感染文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat clamscan.out | grep FOUND</span><br></pre></td></tr></table></figure></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/ComputationalAdvertising/CA——COEC特征.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/ComputationalAdvertising/CA——COEC特征.html" itemprop="url">CA——COEC特征</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<ul>
<li>参考： <a href="http://d0evi1.com/positionbias/" target="_blank" rel="noopener">http://d0evi1.com/positionbias/</a></li>
<li>COEC（Click on Expected Click）：<strong>点击与期望点击的比值</strong></li>
</ul>
<hr>
<h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul>
<li>在评价一个广告的质量好坏时，单纯使用广告的点击率作为指标是不可行的</li>
<li>广告的点击率与广告的曝光位置相关【包括slot或position引起的问题】<ul>
<li>从position上来讲，越靠前的广告越容易被点击</li>
</ul>
</li>
</ul>
<hr>
<h3 id="COEC"><a href="#COEC" class="headerlink" title="COEC"></a>COEC</h3><ul>
<li>为了抵消广告曝光位置对广告的点击率的影响，我们引入期望点击</li>
<li>在计算商家的点击率时，使用<strong>点击与期望点击的比值</strong>作为商家点击率质量的衡量指标<br>$$<br>\begin{align}<br>COEC = \frac{\sum_{i=1}^N isClick_i}{\sum_{i=1}^N expCTR_i}<br>\end{align}<br>$$<ul>
<li>\(isClick_i\)为0或1，表示真实点击情况</li>
<li>\(expCTR_i\)为广告真实曝光位置的期望点击率,不同slot和position对应的期望点击率不同</li>
</ul>
</li>
</ul>
<hr>
<h3 id="COEC特征"><a href="#COEC特征" class="headerlink" title="COEC特征"></a>COEC特征</h3><ul>
<li>在广告相关指标预估模型中，使用COEC作为广告的特征可提升模型的效果</li>
<li>由于COEC的分母上考虑了位置因素，使得COEC更能真实的反应广告实际点击率的真实质量</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/ComputationalAdvertising/CA——术语和专有名词总结.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/ComputationalAdvertising/CA——术语和专有名词总结.html" itemprop="url">CA——术语和专有名词总结</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>本文主要总结计算广告(computational advertising)中的术语和专有名词</em></p>
<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<p>*&lt;&lt;计算广告&gt;&gt;中后面附录有很多计算广告相关的专有名词相关记录*<br><em>本文将长期持续更新,记录平时遇到计算广告专有名词</em></p>
<hr>
<h3 id="英文简写"><a href="#英文简写" class="headerlink" title="英文简写"></a>英文简写</h3><ul>
<li>IOE计算架构: IBM, Oracle, EMC(适用于规模不大但对于一致性和实时性要求较高的场景)</li>
<li>BI: Business Intelligence(商业智能)</li>
<li>DM: Direct Marketing(直接营销)</li>
<li>ROI: Return on Investment(投入产出比 = 总产出/总投入)</li>
<li>EDM: Email Direct Marketing(邮件营销广告)</li>
<li>GD: Guaranteed Delivery(担保式投送)</li>
<li>CPM: Cost per Mille(按千次展示付费)</li>
<li>CPC: Cost per Click</li>
<li>CPS: Cost per Sale</li>
</ul>
<hr>
<h3 id="常见中英文对照"><a href="#常见中英文对照" class="headerlink" title="常见中英文对照"></a>常见中英文对照</h3><ul>
<li>付费内容: sponsored content</li>
<li>商业化: monetization</li>
<li>个性化推荐: personalized recommendation</li>
<li>直接效果广告: direct response</li>
<li>品牌广告: brand awareness</li>
<li>横幅广告: banner ad</li>
<li>交互式广告: playalble ad</li>
<li>激励广告: incentive ad</li>
<li>展示广告: display advertising</li>
<li>合约广告: agreement-based advertising</li>
<li>定向广告: targeted advertising</li>
<li>受众定向: audience targeting</li>
<li>在线分配: online allocation</li>
<li>带约束优化: constrained optimization</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/NLP/NLP——UNILM论文阅读笔记.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/NLP/NLP——UNILM论文阅读笔记.html" itemprop="url">NLP——UNILM论文阅读笔记</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>本文介绍了MSRA今年的一篇文章: <a href="https://arxiv.org/abs/1905.03197" target="_blank" rel="noopener">UNILM: Unified Language Model Pre-training for Natural Language Understanding and Generation</a></em></p>
<script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<hr>
<h3 id="UNILM基于三个预训练目标"><a href="#UNILM基于三个预训练目标" class="headerlink" title="UNILM基于三个预训练目标"></a>UNILM基于三个预训练目标</h3><ul>
<li>Unidirectional LM: </li>
<li>Bidirectional LM: </li>
<li>Sequence2Sequence LM: </li>
</ul>
<hr>
<h3 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h3><h4 id="和BERT对比"><a href="#和BERT对比" class="headerlink" title="和BERT对比"></a>和BERT对比</h4><ul>
<li>BERT是双向模型,所以自然语言的生成(NLG)任务上不适用</li>
<li>UNILM采用三种(无监督的)LM目标,其中的Sequence2Sequence LM能够解决文本生成问题</li>
</ul>
<h4 id="其他一些优点"><a href="#其他一些优点" class="headerlink" title="其他一些优点"></a>其他一些优点</h4><ul>
<li>仅使用一个LM(由Transformer构成), 在三个不同的预训练任务上共享参数, 泛化能力强<ul>
<li>参数共享: 不需要在不同的语言模型(对应不同的预训练任务)上使用不同的模型参数</li>
<li>泛化能力强: 多个训练目标同时优化模型,使得模型能够避开因为训练目标引起的过拟合问题</li>
</ul>
</li>
<li></li>
</ul>
<hr>
<h3 id="模型结构介绍"><a href="#模型结构介绍" class="headerlink" title="模型结构介绍"></a>模型结构介绍</h3><h4 id="结构图"><a href="#结构图" class="headerlink" title="结构图"></a>结构图</h4><img src="/Notes/NLP/NLP——UNILM论文阅读笔记/UNILM_Overview.png">
<ul>
<li>输入向量为 \(\vec{x} = (x_1, x_2,,,x_{|x|}\))</li>
<li>输入向量表征与BERT相同,由Embedding层(三个Embedding层之和, 和BERT一样):<ul>
<li>Token Embedding, WordPiece</li>
<li>Position Embedding</li>
<li>Segment Embedding, 由于UNILM会使用多个LM任务训练,所以Segment Embedding在模型中也扮演着LM标识的作用(对不同的LM目标使用不同的Segment Embeddings)</li>
</ul>
</li>
<li>主要网络(Backbone Network)为多层Transformer:<ul>
<li>每两个Transformer Blocks之间的Self-Attention Masks: For Each Transformer Block, 使用多头Self-Attention来聚合之前层出现的输入向量.(这里的Self-Attention使用了)</li>
<li>Transformer之间的Self-Attention机制决定了模型什么语言模型(任务)</li>
<li>如图所示:<ul>
<li>Bidirectional LM 对应的 Self-Attention Masks为全0的矩阵, 表示所有的Attention都不屏蔽 (attend to all tokens)</li>
<li>Left-to-Right LM 对应的 Self-Attention Masks为拼屏蔽右上三角的矩阵(左下三角全为0)</li>
<li>Right-to-Left LM 对应的 Self-Attention Masks为拼屏蔽左下三角的矩阵(右上三角全为0)</li>
<li>Seq-to-Seq LM 对应的 Self-Attention为 <ul>
<li>\(S_1\)-\(S_1\) 为全0(0表示开放), 对应为Bidirectional</li>
<li>\(S_1\)-\(S_2\) 为负无穷(负无穷表示屏蔽)</li>
<li>\(S_2\)-\(S_1\) 为全0</li>
<li>\(S_2\)-\(S_2\) 为屏蔽右上三角的矩阵(这里与Left-to-Right的情况相同)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="按照结构图分析数据流"><a href="#按照结构图分析数据流" class="headerlink" title="按照结构图分析数据流"></a>按照结构图分析数据流</h4><ul>
<li>对于一组输入向量 \(\{\vec{x}\}_{i=1}^{|x|} \), 初始编码为 \(\mathbf{H}^0 = [\vec{x}_1, \vec{x}_2,,,\vec{x}_{|\vec{x}|}]\)</li>
<li>第一层后编码为上下文表征\(\mathbf{H}^1 = [\vec{h}_1^1, \vec{h}_2^1,,,\vec{h}_{|\vec{x}|}^1]\)</li>
<li>第 \(l\) 层后编码为上下文表征\(\mathbf{H}^l = [\vec{h}_1^l, \vec{h}_2^l,,,\vec{h}_{|\vec{x}|}^l]\)</li>
<li>每一层的 Transformer Block, 使用 multiple self-attention heads去聚合上一层的输出: L-layer的 Transformer对应的数学表达式为 \(\mathbf{H}^l = Transformer_l(\mathbf{H}^{l-1}), l \in [1, L]\)</li>
<li>Self-Attention Head \(\mathbf{A}_l\)的详细计算公式如下:<br>$$<br>\begin{align}<br>\mathbf{H} = \mathbf{H}^{l-1}\mathbf{W}_l^Q \\<br>\mathbf{K} = \mathbf{H}^{l-1}\mathbf{W}_l^K \\<br>\mathbf{V} = \mathbf{H}^{l-1}\mathbf{W}_l^V \\<br>\mathbf{A} = softmax(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}} + \mathbf{M})\mathbf{V}_l \\<br>where, \quad \mathbf{M}_{ij} = 0 \ or \ -\infty<br>\end{align}<br>$$<ul>
<li>\(\mathbf{M}\)中的值<ul>
<li>\(-\infty\) 表示屏蔽Attention (prevent from Attention)</li>
<li>0 表示允许 Attention (allow to Attention)</li>
</ul>
</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/jiahong-head.png" alt="Joe Zhou">
            
              <p class="site-author-name" itemprop="name">Joe Zhou</p>
              <p class="site-description motion-element" itemprop="description">本博客主要用于记录个人学习笔记</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">278</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">48</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/JoeZJH" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="JoeZJiahong@Foxmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Joe Zhou</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
