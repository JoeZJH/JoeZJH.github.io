<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="En/中">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="本博客主要用于记录个人学习笔记">
<meta name="keywords" content="Python, Computer, ML, Linux, Ubuntu, NLP, Git, DL,">
<meta property="og:type" content="website">
<meta property="og:title" content="Jiahong的个人博客">
<meta property="og:url" content="https://JoeZJH.github.io/page/24/index.html">
<meta property="og:site_name" content="Jiahong的个人博客">
<meta property="og:description" content="本博客主要用于记录个人学习笔记">
<meta property="og:locale" content="En/中">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jiahong的个人博客">
<meta name="twitter:description" content="本博客主要用于记录个人学习笔记">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://JoeZJH.github.io/page/24/">





  <title>Jiahong的个人博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="En/中">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jiahong的个人博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">凡事预则立，不预则废</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/DL/DL——关于参数的初始化.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/DL/DL——关于参数的初始化.html" itemprop="url">DL——关于参数的初始化</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<h3 id="为什么参数不能初始化为全0？"><a href="#为什么参数不能初始化为全0？" class="headerlink" title="为什么参数不能初始化为全0？"></a>为什么参数不能初始化为全0？</h3><ul>
<li>因为此时会导致同一隐藏层的神经元互相对称，可以通过递推法证明，不管迭代多少次，此时所有的神经元都将计算完全相同的函数</li>
<li>并不会因为参数都为0就导致所有神经元死亡！</li>
</ul>
<hr>
<h3 id="为什么参数不能初始化为太大的数值？"><a href="#为什么参数不能初始化为太大的数值？" class="headerlink" title="为什么参数不能初始化为太大的数值？"></a>为什么参数不能初始化为太大的数值？</h3><ul>
<li><p>因为参数太大会导致sigmoid(z)或tanh(z)中的z太大，从而导致梯度太小而更新太慢</p>
</li>
<li><p>如果网络中完全没有sigmoid和tanh等激活函数，那就还好，但是要注意，二分类中使用sigmoid函数于输出层时也不应该将参数初始化太大</p>
</li>
<li><p>单层隐藏层的神经网络一般这样初始化：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">W = np.random.randn((n1, n2)) * 0.01</span><br></pre></td></tr></table></figure>

<ul>
<li>适用于单层隐藏层神经网络的参数</li>
<li>如果是深层网络则要考虑使用其他常数而不是<code>0.01</code></li>
</ul>
</li>
</ul>
<hr>
<h3 id="神经网络的层数也可当做参数"><a href="#神经网络的层数也可当做参数" class="headerlink" title="神经网络的层数也可当做参数"></a>神经网络的层数也可当做参数</h3><ul>
<li>不是越深越好</li>
<li>一个问题的开始一般从单层网络开始，即Logistic回归开始</li>
<li>逐步加深网络层数，不断测试效果，寻找合适的网络层数即可</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/DL/DL——不可导函数的可导近似.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/DL/DL——不可导函数的可导近似.html" itemprop="url">DL——不可导函数的可导近似</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <!-- <script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"  type="text/javascript"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<ul>
<li>参考链接：<ul>
<li><a href="https://kexue.fm/archives/6620" target="_blank" rel="noopener">函数光滑化杂谈：不可导函数的可导逼近-科学空间</a>：苏神关于不可导函数逼近可导函数的总结  </li>
</ul>
</li>
</ul>
<hr>
<h3 id><a href="#" class="headerlink" title></a></h3><hr>
<h3 id="AUC的近似"><a href="#AUC的近似" class="headerlink" title="AUC的近似"></a>AUC的近似</h3><ul>
<li>参见：《MBA: Mini-Batch AUC Optimization》</li>
<li>详情见：<a href="https://zhuanlan.zhihu.com/p/74216219" target="_blank" rel="noopener">AUC Optimization - Lanzhe Guo的文章 - 知乎</a></li>
<li>待补充</li>
</ul>
<hr>
<h3 id="其他特殊函数-采样"><a href="#其他特殊函数-采样" class="headerlink" title="其他特殊函数-采样"></a>其他特殊函数-采样</h3><ul>
<li>实际上，可以把采样也看做一个不可导函数，采样的可导近似方法一般称为重参数化技巧</li>
<li>采样包含连续型分布采样和离散分布采样，分别有不同的重参数化技巧</li>
<li>离散分布采样的一种重参数化技巧叫做Gumbel softmax trick（其中使用到了argmax函数的可导近似函数softmax）</li>
<li>详情可参考<a href="/Notes/DL/DL%E2%80%94%E2%80%94%E9%87%8D%E5%8F%82%E6%95%B0%E5%8C%96%E6%8A%80%E5%B7%A7.html">DL——重参数化技巧</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/DL/DL——各种梯度下降相关的优化算法.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/DL/DL——各种梯度下降相关的优化算法.html" itemprop="url">DL——各种梯度下降相关的优化算法</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>本文从梯度下降(Gradient Descent, GD)开始,讲述深度学习中的各种优化算法（优化器，Optimizer）</em></p>
<!-- <script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"  type="text/javascript"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


<p>参考文章:<a href="https://m.sohu.com/a/131923387_473283/?pvid=000115_3w_a" title="https://m.sohu.com/a/131923387_473283/?pvid=000115_3w_a" target="_blank" rel="noopener">【干货】深度学习必备：随机梯度下降（SGD）优化算法及可视化</a> </p>
<hr>
<h3 id="三种梯度下降框架"><a href="#三种梯度下降框架" class="headerlink" title="三种梯度下降框架"></a>三种梯度下降框架</h3><h4 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h4><h5 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h5><ul>
<li>每次从随机从训练集中选择一个训练样本来计算误差,进而更新模型参数</li>
<li>单次迭代时参数移动方向可能不太精确甚至相反,但是最终会收敛</li>
<li>单次迭代的波动也带来了一个好处,可以到达一个更好的局部最优点,甚至到达全局最优点</li>
</ul>
<h5 id="参数更新公式"><a href="#参数更新公式" class="headerlink" title="参数更新公式"></a>参数更新公式</h5><p><em>Stochastic Gradient Descent, SGD</em></p>
<ul>
<li>公式: \(\theta=\theta-\lambda\frac{\partial L(\theta;x_{i};y_{i})}{\partial \theta}\)</li>
<li>其中:\(L(\theta;x_{i};y_{i})=L(f(\theta;x_{i}),y_{i})\)</li>
</ul>
<h4 id="批量梯度下降"><a href="#批量梯度下降" class="headerlink" title="批量梯度下降"></a>批量梯度下降</h4><p><em>Batch Gradient Descent, BGD</em></p>
<h5 id="核心思想-1"><a href="#核心思想-1" class="headerlink" title="核心思想"></a>核心思想</h5><ul>
<li>每次使用全量的训练集样本(假设共m个)来计算误差,进而更新模型参数</li>
<li>每次参数能够朝着正确的方向移动</li>
<li>每次遍历所有数据,耗费时间较长</li>
</ul>
<h5 id="参数更新公式-1"><a href="#参数更新公式-1" class="headerlink" title="参数更新公式"></a>参数更新公式</h5><ul>
<li>公式: \(\theta=\theta-\lambda\frac{\partial L(\theta;x_{1:m};y_{1:m})}{\partial \theta}\)</li>
<li>一般来说: \(L(\theta;x_{1:m};y_{1:m}) = \frac{1}{m}\sum_{i=1}^{m} L(\theta;x_{i};y_{i})\)</li>
</ul>
<h4 id="小批量梯度下降"><a href="#小批量梯度下降" class="headerlink" title="小批量梯度下降"></a>小批量梯度下降</h4><h5 id="核心思想-2"><a href="#核心思想-2" class="headerlink" title="核心思想"></a>核心思想</h5><ul>
<li>每次从随机从训练集中选择k(k &lt; m)个训练样本来计算误差,进而更新模型参数</li>
<li>介于SGD和BGD之间<ul>
<li>波动小</li>
<li>内存占用也相对较小</li>
</ul>
</li>
</ul>
<h5 id="参数更新公式-2"><a href="#参数更新公式-2" class="headerlink" title="参数更新公式"></a>参数更新公式</h5><p><em>Mini-Batch Gradient Descent, MBGD</em></p>
<ul>
<li>公式: \(\theta=\theta-\lambda\frac{\partial L(\theta;x_{i:i+k};y_{i:i+k})}{\partial \theta}\)</li>
<li>一般来说: \(L(\theta;x_{1:k};y_{1:k}) = \frac{1}{k}\sum_{i=1}^{k} L(\theta;x_{i};y_{i})\)</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ul>
<li>梯度下降算法应用广泛,算法效果很好</li>
</ul>
<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><h6 id="学习速率"><a href="#学习速率" class="headerlink" title="学习速率"></a>学习速率</h6><ul>
<li>大小很难确定,太大容易震荡,太小则收敛太慢</li>
<li>学习速率一般为定值,有时候会实现为逐步衰减</li>
<li>但是无论如何,都需要事前固定一个值,因此无法自适应不同的数据集特点</li>
</ul>
<h6 id="局部最优"><a href="#局部最优" class="headerlink" title="局部最优"></a>局部最优</h6><ul>
<li>对于非凸的目标函数,容易陷入局部极值点中</li>
<li>比局部极值点更严重的问题:有时候会嵌入鞍点?</li>
</ul>
<hr>
<h3 id="SD算法的优化"><a href="#SD算法的优化" class="headerlink" title="SD算法的优化"></a>SD算法的优化</h3><h4 id="Momentum法-动量法"><a href="#Momentum法-动量法" class="headerlink" title="Momentum法(动量法)"></a>Momentum法(动量法)</h4><h5 id="核心思想-3"><a href="#核心思想-3" class="headerlink" title="核心思想"></a>核心思想</h5><ul>
<li>考虑一种情况,在峡谷地区(某些方向比另一些方向陡峭很多)<ul>
<li>SGD(或者MBGD,实际上,SGD是特殊的MBGD,平时可以认为这两者是相同的东西)会在这些放附近振荡,从而导致收敛速度变慢</li>
<li>这里最好的例子是鞍点,鞍点出的形状像一个马鞍,一个方向两头上翘,一个方向两头下垂,当上翘的方向比下垂的方向陡峭很多时,SDG和MDG等方法容易在上翘方向上震荡</li>
</ul>
</li>
<li>此时动量可以使得<ul>
<li>当前梯度方向与上一次梯度方向相同的地方进行加强,从而加快收敛速度</li>
<li>当前梯度方向与上一次梯度方向不同的地方进行削减,从而减少振荡</li>
</ul>
</li>
<li>动量可以理解为一个从山顶滚下的小球,遇到新的力(当前梯度)时,会结合之前的梯度方向决定接下来的运动方向</li>
</ul>
<h5 id="参数更新公式-3"><a href="#参数更新公式-3" class="headerlink" title="参数更新公式"></a>参数更新公式</h5><ul>
<li>公式: \(\theta=\theta-m_{t}\)<ul>
<li>\(m_{t}\)表示当前下降方向, \(m_{t-1}\)表示上一次的下降方向</li>
<li>\(m_{t}=\gamma m_{t-1}+\lambda\frac{\partial L(\theta;x_{i};y_{i})}{\partial \theta}\)</li>
<li>\(\gamma&lt;1\),值一般取0.9</li>
<li>\(\gamma m_{t-1}\)是动量项</li>
<li>\(\gamma\)是衰减量</li>
<li>\(\lambda\)是学习率</li>
</ul>
</li>
</ul>
<h5 id="图示"><a href="#图示" class="headerlink" title="图示"></a>图示</h5><img src="/Notes/DL/DL——各种梯度下降相关的优化算法/momentum_sgd.png" title="momentum_sgd.png">
<img src="/Notes/DL/DL——各种梯度下降相关的优化算法/momentum_description.png" title="momentum_description.png">
<h5 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h5><ul>
<li>学习过程<ul>
<li>从训练集中的随机抽取一批容量为m的样本\({x_{1},…,x_{m}}\),以及相关的输出\({y_{1},…,y_{m}}\)</li>
<li>计算梯度和误差,更新v和参数\(\theta\)</li>
</ul>
</li>
</ul>
<h4 id="NAG-涅斯捷罗夫梯度加速法"><a href="#NAG-涅斯捷罗夫梯度加速法" class="headerlink" title="NAG,涅斯捷罗夫梯度加速法"></a>NAG,涅斯捷罗夫梯度加速法</h4><p><em>Nesterov Accelerated Gradient,NAG</em></p>
<h5 id="核心思想-4"><a href="#核心思想-4" class="headerlink" title="核心思想"></a>核心思想</h5><ul>
<li>继续考虑普通的SDG算法,添加了Momentum,此时从山顶滚下的球会盲目的选择斜坡</li>
<li>更好的方式是在遇到向上的斜坡时减慢速度</li>
<li>NAG在计算梯度时首先获取(近似获得)未来的参数而不是当前参数,然后计算未来参数对应的损失函数的梯度</li>
<li>NAG在预测了未来的梯度后,根据<strong>未来</strong>(\(\theta - \gamma m_{t-1}\))梯度方向和之前梯度的方向决定当前的方向, 这样可以保证在遇到下一点为上升斜坡时适当减慢当前点的速度(否则可能由于惯性走上斜坡, 提前知道\(\theta - \gamma m_{t-1}\)处的梯度, 从而保证不要走上去), 从而找到了比Momentum超前的更新方向</li>
<li>对比: Momentum是根据<strong>当前</strong>梯度方向和之前梯度方向决定当前的方向</li>
</ul>
<h5 id="参数更新公式-4"><a href="#参数更新公式-4" class="headerlink" title="参数更新公式"></a>参数更新公式</h5><ul>
<li>公式: \(\theta=\theta-m_{t}\)<ul>
<li>\(m_{t}=\gamma m_{t-1}+\lambda\frac{\partial L(\theta - \gamma v_{t-1};x_{i};y_{i})}{\partial \theta}\)</li>
<li><strong>NAG</strong>使用的是<strong>未来</strong>的梯度方向(<strong>Momentum</strong>使用的是<strong>当前</strong>梯度方向)和之前的梯度方向</li>
</ul>
</li>
</ul>
<h5 id="图示-1"><a href="#图示-1" class="headerlink" title="图示"></a>图示</h5><ul>
<li>Momentum(动量)法首先计算当前的梯度值(小蓝色向量)，然后在更新的积累向量（大蓝色向量）方向前进一大步</li>
<li>NAG 法则首先(试探性地)在之前积累的梯度方向(棕色向量)前进一大步，再根据当前地情况修正，以得到最终的前进方向(绿色向量)</li>
<li>这种基于预测的更新方法，使我们避免过快地前进，并提高了算法地响应能力(responsiveness)，大大改进了 RNN 在一些任务上的表现<img src="/Notes/DL/DL——各种梯度下降相关的优化算法/nag.png" title="nag.png">
<img src="/Notes/DL/DL——各种梯度下降相关的优化算法/nag_description.png" title="nag_description.png">
<ul>
<li>公式中\(-\gamma m_{t-1}\)对应BC向量</li>
<li>\(\theta-\gamma m_{t-1}\)就对应C点(参数)</li>
</ul>
</li>
</ul>
<h5 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h5><ul>
<li>Momentum和NAG法可以使得参数更新过程中根据随时函数的斜率自适应的学习,从而加速SGD的收敛</li>
<li>实际应用中,NAG将比Momentum收敛快很多</li>
<li>学习过程<ul>
<li>从训练集中的随机抽取一批容量为m的样本\({x_{1},…,x_{m}}\),以及相关的输出\({y_{1},…,y_{m}}\)</li>
<li>计算梯度和误差,更新v和参数\(\theta\)</li>
</ul>
</li>
</ul>
<h4 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h4><h5 id="核心思想-5"><a href="#核心思想-5" class="headerlink" title="核心思想"></a>核心思想</h5><ul>
<li>对于较少出现的特征,使用较大的学习率更新,即对低频的参数给予更大的更新</li>
<li>对于较多出现的特征,使用较小的学习率更新,即对高频的参数给予更小的更新</li>
<li>很适合处理稀疏数据</li>
</ul>
<h5 id="参数更新公式-5"><a href="#参数更新公式-5" class="headerlink" title="参数更新公式"></a>参数更新公式</h5><ul>
<li>计算梯度<ul>
<li>分量形式: \(g_{t,k} = \frac{\partial L(\theta;x_{i};y_{i})}{\theta}|_{\theta = \theta_{t-1,k}}\)<ul>
<li>\(g_{t,k}\)是指第t次迭代时第k个参数\(\theta_{t-1, k}\)的梯度</li>
<li>有些地方会这样表达: \(g_{t,k} = \frac{\partial L(\theta_{t-1,k};x_{i};y_{i})}{\theta_{t-1,k}}\)<ul>
<li>式子中使用\(\theta_{t-1, k}\)在梯度中,事实上不够严谨, 容易让人误解分子分母都不是函数,而是一个确定的值, 事实上我们是先求了导数然后再带入 \(\theta = \theta_{t-1}\) 的</li>
</ul>
</li>
</ul>
</li>
<li>向量形式: \(g_{t} = \frac{\partial L(\theta;x_{i};y_{i})}{\partial \theta}|_{\theta=\theta_{t-1}}\)</li>
</ul>
</li>
<li>此时普通的SGD如下更新参数<ul>
<li>分量形式:\(\theta_{t,k} = \theta_{t-1,k} - \lambda g_{t,k}\)</li>
<li>向量形式:\(\theta_{t} = \theta_{t-1} - \lambda g_{t}\)</li>
</ul>
</li>
<li>而Adagrad对学习率\(\lambda\)根据不同参数进行了修正<ul>
<li>分量形式:\(\theta_{t,k} = \theta_{t-1,k} - \frac{\lambda}{\sqrt{G_{t,kk}+\epsilon}} g_{t,k}\)<ul>
<li>\(G_{t,kk}=\sum_{r=1}^{t}(g_{r,k})^{2}\)</li>
</ul>
</li>
<li>向量形式:\(\theta_{t} = \theta_{t-1} - \frac{\lambda}{\sqrt{G_{t}+\epsilon}}\bigodot g_{t}\)<ul>
<li>\(G_{t}=\sum_{r=1}^{t}g_{r}\bigodot g_{r}\)</li>
<li>\(\bigodot\)表示按照对角线上的值与对应梯度相乘</li>
<li>进一步可以简化写为: \(G_t = G_{t-1} + g_t^2\)<ul>
<li>注意: 这里\(g_t^2\)是指向量按照维度分别相乘, 计算后还是原始向量维度</li>
</ul>
</li>
</ul>
</li>
<li>G是一个对角矩阵,对角线上的元素(\(G_{k,k}\))是从一开始到k次迭代目标函数对于参数(\(\theta_{k}\))的梯度的平方和<ul>
<li>G的累计效果保证了出现次数多的参数(\(\theta_{k}\))对应的对角线上的元素(\(G_{k,k}\))大,从而得到更小的更新</li>
</ul>
</li>
<li>\(\epsilon\)是一个平滑项,用于防止分母为0</li>
</ul>
</li>
<li>总结参数更新公式:<ul>
<li>\(\theta_{t} = \theta_{t-1} - \frac{\lambda}{\sqrt{G_{t}+\epsilon}} g_{t}\)</li>
<li>\(g_{t} = \frac{\partial L(\theta;x_{i};y_{i})}{\partial \theta }|_{\theta = \theta_{t-1}}\)</li>
<li>\(G_t = G_{t-1} + g_t^2\)</li>
</ul>
</li>
</ul>
<h5 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h5><ul>
<li>在分母上<strong>累计了平方梯度和</strong>,造成训练过程中<strong>G的对角线元素越来越大</strong>,最终导致<strong>学习率非常小</strong>,甚至是无限小的值,从而<strong>学不到东西</strong></li>
<li>学习过程<ul>
<li>从训练集中的随机抽取一批容量为m的样本\({x_{1},…,x_{m}}\),以及相关的输出\({y_{1},…,y_{m}}\)</li>
<li>计算梯度和误差,更新G的每个元素,再根据G以及梯度计算参数更新量 </li>
</ul>
</li>
</ul>
<h4 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h4><h5 id="核心思想-6"><a href="#核心思想-6" class="headerlink" title="核心思想"></a>核心思想</h5><ul>
<li>是Adagrad的一个扩展,目标是解决Adagrad学习率单调下降的问题</li>
<li>解决方案:只累计一段时间内的平方梯度值?</li>
<li>实际上实现是累加时给前面的平方梯度和一个衰减值</li>
<li>方法名delta的来源是选取部分</li>
</ul>
<h5 id="参数更新公式-6"><a href="#参数更新公式-6" class="headerlink" title="参数更新公式"></a>参数更新公式</h5><ul>
<li>将矩阵G的每一项变成当前梯度平方加上过去梯度平方的衰减值(指数衰减)即可<ul>
<li>指数衰减:前n-1项的系数是衰减率的n-1次方</li>
<li>实现指数衰减</li>
<li>在Adagrad的基础上修改为: \(G_t = \gamma G_{t-1} + (1-\gamma)g_t^2\)<ul>
<li>注意: 这里\(g_t^2\)是指向量按照维度分别相乘, 计算后还是原始向量维度</li>
</ul>
</li>
<li>我们通常也把 \(G_t\) 表达为 \(E[g^2]_t\)<ul>
<li>因为修改后的 \(G_t\)可以视为于对 \(g_t^2\) 求期望(不同的\(t\)概率权重不一样的分布的期望)</li>
<li>进一步表达为: \(E[g^2]_t = \gamma E[g^2]_{t-1} + (1-\gamma)g_t^2\)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h5><ul>
<li>经过衰减后,G的每一项(忽略掉平滑项\(\epsilon\))相当于有权重的梯度均方差(Root Mean Square, RMS),后面RMSprop算法就用了这个RMS来命名<ul>
<li>均方根的定义是:对所有数求平方和,取平均值(每一项的权重根据概率分布可以不同),再开方</li>
</ul>
</li>
<li>学习过程<ul>
<li>从训练集中的随机抽取一批容量为m的样本\({x_{1},…,x_{m}}\),以及相关的输出\({y_{1},…,y_{m}}\)</li>
<li>计算梯度和误差,更新G的每个元素,再根据G以及梯度计算参数更新量 </li>
</ul>
</li>
</ul>
<h4 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h4><p><em>Root Mean Square prop</em></p>
<h5 id="核心思想-7"><a href="#核心思想-7" class="headerlink" title="核心思想"></a>核心思想</h5><ul>
<li>一种适应性学习率方法,至今未公开发表</li>
<li>是Adagrad的一个扩展,目标也是解决Adagrad学习率单调下降的问题</li>
<li>RMS的来源是由于分母相当于(忽略掉平滑项\(\epsilon\))是梯度的均方根(Root Mean Squared, RMS)</li>
</ul>
<h5 id="参数更新公式-7"><a href="#参数更新公式-7" class="headerlink" title="参数更新公式"></a>参数更新公式</h5><ul>
<li>参见Adadelta</li>
<li>RMSprop的本质是对Adadelta简单的取之前值和当前值的权重为0.9和0.1实现指数加权平均, 即 \(\gamma = 0.9\)</li>
<li>有些地方也说RMSprop权重取的是0.5和0.5实现指数加权平均即 \(\gamma = 0.5\)</li>
<li>学习率\(\lambda\)一般取值为0.001</li>
</ul>
<h5 id="小结-4"><a href="#小结-4" class="headerlink" title="小结"></a>小结</h5><ul>
<li><strong>RMSprop是Adadelta的一种特殊形式</strong></li>
<li>Adagrad的分母不能算是均方差(即使忽略平滑项\(\epsilon\)),因为这里没有取平均值的操作</li>
<li>学习过程<ul>
<li>从训练集中的随机抽取一批容量为m的样本\({x_{1},…,x_{m}}\),以及相关的输出\({y_{1},…,y_{m}}\)</li>
<li>计算梯度和误差,更新G的每个元素,再根据G以及梯度计算参数更新量 </li>
</ul>
</li>
</ul>
<h4 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h4><p><em>Adaptive Moment Estimation</em></p>
<h5 id="核心思想-8"><a href="#核心思想-8" class="headerlink" title="核心思想"></a>核心思想</h5><ul>
<li>一种适应性学习率方法,相当于 <strong>RMSprop + Momentum + Bias Correction</strong></li>
<li>像Adadelta和RMSprop一样存储了梯度的平方的指数衰减平均值</li>
<li>像Momentum一样保持了过去梯度的指数衰减平均值</li>
<li>Bias Correction是为了得到期望的<strong>无偏估计</strong></li>
</ul>
<h5 id="参数更新公式-8"><a href="#参数更新公式-8" class="headerlink" title="参数更新公式"></a>参数更新公式</h5><ul>
<li>\(\theta_{t} = \theta_{t-1} - \frac{\lambda}{\sqrt{\tilde{v}_t+\epsilon}} \tilde{m}_t\)</li>
<li>\(\tilde{v}_t=\frac{v_{t}}{1-\beta_{1}^{t}}\)</li>
<li>\(\tilde{m}_t=\frac{m_{t}}{1-\beta_{2}^{t}}\)</li>
<li>\(\lambda\)是外层学习率，实际使用中，常常可以通过指数衰减、固定步长衰减、余弦退火衰减等学习率衰减策略更新</li>
<li>梯度的指数衰减:\(m_{t} = \beta_{2}m_{t-1}+(1-\beta_{2})g_{t}\)</li>
<li>梯度平方的指数衰减:\(v_{t} = \beta_{1}v_{t-1}+(1-\beta_{1})g_{t}^{2}\)<ul>
<li>\(m_t\) 和 \(v_t\) 也叫作一阶动量和二阶动量，是对梯度一阶矩估计和二阶矩估计<ul>
<li>数学定义：随机变量的一阶矩是随机变量的期望\(E[X]\)，二阶矩是随机变量的方差\(E[X-E[X]]\)</li>
<li>其实梯度平方的期望不是梯度的方差，这只是一种近似，数学上，随机变量\(X\)二阶矩等价于方差，是\(E[(X-E[X])^2] = E[X^2]-E[X]^2\)，当\(E[X]=0\)时，\(E[X^2]\)就是方差</li>
<li>这种滑动平均之所以能代表期望，是因为滑动平均的思想是一种折扣平均，确实可以用来作为期望和方差的估计</li>
</ul>
</li>
<li>\(m_t\) 和 \(v_t\) 可以看做是对 \(E[g]_t\) 和 \(E[g^2]_t\) 的估计</li>
<li>\(\tilde{m}_t\) 和 \(\tilde{v}_t\) 是对 \(m_t\) 和 \(v_t\) 的 <strong>Bias Correction</strong>, 这样可以近似为对对期望 \(E[g]_t\) 和 \(E[g^2]_t\) 的<strong>无偏估计</strong><ul>
<li>注意：修正项\(\tilde{v}_t=\frac{v_{t}}{1-\beta_{1}^{t}}\)中的\(\beta_{1}^{t}\)是\(\beta_{1}\)的\(t\)次方的意思，基本思路可以理解为在每一步都尽量将梯度修正到\(t=0\)大小</li>
<li>进行修正的原因是当\(t\)较小时，\(v_t\)也较小，而\(\beta\)一般较大（0.9或者0.999），此时加权平均的结果也会很小，当\(t\)很大时，实际上可以不用修正了，个人理解：应该可以不用修正，只是前期训练时更新速度比较慢而已</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="小结-5"><a href="#小结-5" class="headerlink" title="小结"></a>小结</h5><ul>
<li>超参数设定推荐<ul>
<li>梯度平方衰减率:\(\beta_{1}=0.999\)</li>
<li>梯度动量衰减率:\(\beta_{2}=0.9\)</li>
<li>平滑项:\(\epsilon=10e^-8=1*10^{-8}\)</li>
<li>一阶动量\(v\),初始化为0</li>
<li>二阶动量\(m\),初始化为0</li>
</ul>
</li>
<li>学习过程<ul>
<li>从训练集中的随机抽取一批容量为m的样本\({x_{1},…,x_{m}}\),以及相关的输出\({y_{1},…,y_{m}}\)</li>
<li>计算梯度和误差,更新\(v\)和\(m\),再根据\(v\)和\(m\)以及梯度计算参数更新量 </li>
</ul>
</li>
</ul>
<h4 id="AdamW"><a href="#AdamW" class="headerlink" title="AdamW"></a>AdamW</h4><p><em>Adam with Weight decay是Adam的一种优化</em></p>
<h5 id="Adam中的L2正则"><a href="#Adam中的L2正则" class="headerlink" title="Adam中的L2正则"></a>Adam中的L2正则</h5><ul>
<li><p>一般的L2正则<br>$$<br>Loss(w) = f(w) + \frac{1}{2}\eta||w||^2<br>$$</p>
</li>
<li><p>权重衰减后的参数更新如下<br>$$<br>\begin{align}<br>w &amp;= w - \alpha\nabla Loss(w) \\<br>&amp;= w - \alpha (\nabla f(w) + \eta w) \\<br>&amp;= w - \alpha \nabla f(w) - \alpha \eta w \\<br>\end{align}<br>$$</p>
</li>
<li><p>由于L2正则化项的存在，每次权重更新时都会减去一定比例的权重，即 \(\alpha \eta w \) ，这种现象叫做权重衰减（L2正则的目标就是让权重往小的方向更新，所以L2正则也叫作权重衰减）</p>
</li>
<li><p>L2正则也称为权重衰减，所以Adam优化的损失函数中添加L2正则的目标本应该也是为了权重衰减</p>
</li>
<li><p>Adam中的L2正则</p>
<ul>
<li>在每次求损失函数梯度前都计算\(\nabla Loss(w) = \nabla f(w) + \eta w\)</li>
<li>由于L2正则项的梯度\(\eta w\)也会被累加到一阶动量和二阶动量中，带有L2的Adam不再是简单的权重衰减，L2正则项还会影响到其他值的更新</li>
<li>Adam中的L2正则会产生我们不期望的结果，因为此时L2正则项影响了Adam参数的正常更新（我们想要L2做的仅仅是权重衰减，但在Adam中，L2产生了别的影响，这个不是我们想要的）</li>
</ul>
</li>
</ul>
<h5 id="AdamW——Adam-权重衰减"><a href="#AdamW——Adam-权重衰减" class="headerlink" title="AdamW——Adam+权重衰减"></a>AdamW——Adam+权重衰减</h5><ul>
<li>AdamW则不直接将L2添加到损失函数中，而是显示的把权重衰减提出来，主要修改是下面两步<ul>
<li>在计算梯度时，将L2正则从损失函数中去除</li>
<li>在更新参数时，显示增加权重衰减项</li>
</ul>
</li>
<li>相当于在更新参数时增加了L2正则，但是计算梯度时没有L2正则</li>
<li>原始论文：<a href="https://arxiv.org/pdf/1711.05101.pdf" target="_blank" rel="noopener">Decoupled Weight Decay Regularization</a><img src="/Notes/DL/DL——各种梯度下降相关的优化算法/SGDW-AdamW.png">
<ul>
<li>图中紫色是原始Adam+L2实现部分，在AdamW中会被去除；</li>
<li>绿色是AdamW中新增的权重衰减部分（相当于更新参数时增加了L2正则项）</li>
</ul>
</li>
<li>参考链接：<a href="https://zhuanlan.zhihu.com/p/643452086" target="_blank" rel="noopener">Adam和AdamW</a>，<a href="https://zhuanlan.zhihu.com/p/653605711" target="_blank" rel="noopener">从梯度下降到AdamW一文读懂机器学习优化算法</a></li>
<li>目前大模型常用的就是AdamW</li>
</ul>
<hr>
<h3 id="优化器与内存-显存"><a href="#优化器与内存-显存" class="headerlink" title="优化器与内存/显存"></a>优化器与内存/显存</h3><ul>
<li>训练的过程中，需要的内存/显存大小与优化器（Optimizer）有关<ul>
<li>需要存储到内存的变量包括以下几个方面<ul>
<li>梯度</li>
<li>参数</li>
<li>优化器状态（Optimizer States)，普通SGD没有这一项，而Adam和AdamW则需要存储一阶动量和二阶动量</li>
</ul>
</li>
</ul>
</li>
<li>优化器、参数量、内存/显存消耗、混合精度训练相关概念可参考<a href="https://arxiv.org/pdf/1910.02054.pdf" target="_blank" rel="noopener">ZeRO: Memory Optimizations Toward Training Trillion Parameter Models</a><ul>
<li>有些论文中也会直接将二阶动量叫做方差(Variance)或者二阶矩，因为二阶动量可以近似方差（当期望为0时）</li>
</ul>
</li>
<li>ZeRO论文中指出，在混合精度训练 + Adam/AdamW时，需要存储的变量包括<ul>
<li>FP16的参数</li>
<li>FP16的梯度</li>
<li>FP32的参数</li>
<li>FP32的一阶动量</li>
<li>FP32的二阶动量</li>
<li>注意：动量不能使用FP16吗？是的，不能，因为为了精度考虑使用时还是要被转换到FP32</li>
</ul>
</li>
</ul>
<hr>
<h3 id="各种优化方法的比较"><a href="#各种优化方法的比较" class="headerlink" title="各种优化方法的比较"></a>各种优化方法的比较</h3><h4 id="鞍点"><a href="#鞍点" class="headerlink" title="鞍点"></a>鞍点</h4><ul>
<li>SGD optimization on saddle point<img src="/Notes/DL/DL——各种梯度下降相关的优化算法/gd_comparations_a.gif" title="gd_comparations_a.gif">

</li>
</ul>
<h4 id="等高线表面"><a href="#等高线表面" class="headerlink" title="等高线表面"></a>等高线表面</h4><ul>
<li><p>SGD optimization on loss surface contours</p>
<img src="/Notes/DL/DL——各种梯度下降相关的优化算法/gd_comparations_b.gif" title="gd_comparations_b.gif">
</li>
<li><p>上面两种情况都可以看出，Adagrad, Adadelta, RMSprop 几乎很快就找到了正确的方向并前进，收敛速度也相当快，而其它方法要么很慢，要么走了很多弯路才找到</p>
</li>
<li><p>由图可知自适应学习率方法即 Adagrad, Adadelta, RMSprop, Adam 在这种情景下会更合适而且收敛性更好</p>
</li>
</ul>
<h4 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h4><ul>
<li>如果数据是稀疏的，就用自适用方法，即 Adagrad, Adadelta, RMSprop, Adam<ul>
<li>因为他们能够为出现更新次数少(确切的说是梯度累计结果小)的特征分配更高的权重</li>
</ul>
</li>
<li>RMSprop, Adadelta, Adam 在很多情况下的效果是相似的</li>
<li>Adam 可解释为 <strong>RMSprop + Momentum + Bias Correction</strong></li>
<li>随着梯度变的稀疏，Adam 比 RMSprop 效果会好</li>
<li><strong>整体来讲，Adam 是最好的选择</strong></li>
<li>很多论文里都会用 SGD，没有 momentum 等, SGD 虽然能达到极小值，但是比其它算法用的时间长，而且可能会被困在鞍点, 在不正确的方向上来回震荡</li>
<li>如果需要更快的收敛，或者是训练更深更复杂的神经网络，需要用一种自适应的算法</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/DL/DL——特殊函数的反向传播.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/DL/DL——特殊函数的反向传播.html" itemprop="url">DL——特殊函数的反向传播</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <hr>
<h3 id="pooling"><a href="#pooling" class="headerlink" title="pooling"></a>pooling</h3><ul>
<li>参考文献：<a href="https://blog.csdn.net/xunan003/article/details/86597954" target="_blank" rel="noopener">普通max pooling反向传播与RoI max pooling反向传播解读</a></li>
</ul>
<h3 id="argmax"><a href="#argmax" class="headerlink" title="argmax"></a>argmax</h3><ul>
<li>参考文献：<a href="https://blog.csdn.net/weixin_39326879/article/details/105968540?spm=1001.2101.3001.6661.1&utm_medium=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~default-1.pc_relevant_aa&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-2~default~CTRLIST~default-1.pc_relevant_aa&utm_relevant_index=1" target="_blank" rel="noopener">pytorch使用argmax argsoftmax</a></li>
<li>参考文献：Cross DQN</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/DL/DL——迁移学习-元学习-联邦学习.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/DL/DL——迁移学习-元学习-联邦学习.html" itemprop="url">DL——迁移学习-元学习-联邦学习</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="迁移学习-元学习-联邦学习对比"><a href="#迁移学习-元学习-联邦学习对比" class="headerlink" title="迁移学习-元学习-联邦学习对比"></a>迁移学习-元学习-联邦学习对比</h3><ul>
<li>迁移学习侧重于知识从源任务到目标任务的迁移</li>
<li>元学习侧重于快速适应新任务的能力</li>
<li>联邦学习则侧重于在数据隐私保护的前提下进行分布式学习。</li>
</ul>
<h4 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h4><ul>
<li>迁移学习（Transfer Learning）允许模型在一个任务上学习得到的知识应用到另一个不同但相关的任务上。这种方法特别适用于目标任务的数据量不足时。在迁移学习中，通常有一个源域（source domain）和一个目标域（target domain），模型首先在源域上进行训练，然后将学到的特征或参数迁移到目标域以提高学习效率和性能。</li>
<li>参考博客: <a href="https://blog.csdn.net/dakenz/article/details/85954548" target="_blank" rel="noopener">https://blog.csdn.net/dakenz/article/details/85954548</a></li>
</ul>
<h4 id="元学习"><a href="#元学习" class="headerlink" title="元学习"></a>元学习</h4><ul>
<li>元学习（Meta-Learning），又称为“学会学习”，是指模型不仅学习如何处理具体的任务，而且学习如何从经验中快速适应和学习新任务的过程。元学习特别关注于当面对新任务时，如何利用已有的知识来加速学习过程。元学习的一个典型应用是通过少量的样本（例如，少样本学习）快速适应新任务。</li>
<li>参考链接：<a href="https://www.bilibili.com/video/BV1UN4y1A7hr/?vd_source=b4442974569859635a5e307b2d4e3b56" target="_blank" rel="noopener">【李宏毅-元学习】少样本&amp;元学习Meta Learning_MAML最新机器学习课程！！！</a></li>
</ul>
<h4 id="联邦学习"><a href="#联邦学习" class="headerlink" title="联邦学习"></a>联邦学习</h4><ul>
<li>联邦学习（Federated Learning）是一种分布式机器学习范式，它允许多个参与者在保持数据隐私和数据本地化的前提下共同构建机器学习模型。在联邦学习中，数据不需要集中存储或处理，而是在各个参与者的本地进行训练，只有模型的更新（如参数）在参与者之间共享。这种方式可以解决数据孤岛问题，同时保护用户隐私。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/DL/DL——深度学习中降低过拟合的方法.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/DL/DL——深度学习中降低过拟合的方法.html" itemprop="url">DL——深度学习中降低过拟合的方法</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="添加Dropout"><a href="#添加Dropout" class="headerlink" title="添加Dropout"></a>添加Dropout</h4><ul>
<li>详情可参考: <a href="/DL/DL%E2%80%94%E2%80%94%E4%B8%BA%E4%BB%80%E4%B9%88Dropout%E8%83%BD%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88.html">DL——为什么Dropout能防止过拟合</a></li>
</ul>
<h4 id="参数范书惩罚"><a href="#参数范书惩罚" class="headerlink" title="参数范书惩罚"></a>参数范书惩罚</h4><p><em>相关参数: Weight decay(权重衰减)</em><br><em>添加L2或L1正则化, 详情可参考: <a href="/Notes/ML/ML%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%B9%E5%B7%AE%E4%B8%8E%E5%81%8F%E5%B7%AE.html">ML——模型的方差与偏差</a></em></p>
<ul>
<li><p>参考文档：</p>
<ul>
<li>L1正则化与L2正则化的详细讲解（L1具有稀疏性，L2让参数更小）：<a href="https://www.cnblogs.com/nxf-rabbit75/p/9954394.html" target="_blank" rel="noopener">L1正则化和L2正则化</a></li>
<li>L1具有稀疏性的证明：<a href="https://blog.csdn.net/b876144622/article/details/81276818" target="_blank" rel="noopener">L1正则为什么更容易获得稀疏解</a><ul>
<li>求导后可知，在0点附近，权重大于0和小于0会产生正负不同的梯度值（当原始损失函数关于当前权重在0点的偏导绝对值小于正则化权重时，整体梯度基本由正则化梯度主导），从而使得参数倾向于走到0点</li>
</ul>
</li>
</ul>
</li>
<li><p>L1正则化: </p>
<ul>
<li>L1又称为: <strong>Lasso Regularization(稀疏规则算子)</strong></li>
<li>计算公式为: <strong>参数绝对值求和</strong> </li>
<li>意义: 趋向于让一些参数为0, 可以起到特征选择的作用</li>
</ul>
</li>
<li><p>L2正则化:</p>
<ul>
<li>L2又称为: <strong>Ridge Regression(岭回归)</strong></li>
<li>Weight decay 是放在正则项(Regularization)前面的一个系数,正则项一般指模型的复杂度</li>
<li>Weight decay 控制模型复杂度对损失函数的影响, 若Weight Decay很大,则模型的损失函数值也就大</li>
<li>pytorch中实现了L2正则化，也叫做权重衰减，具体实现是在优化器中，参数是 <code>weight_decay</code>, 默认为0</li>
</ul>
</li>
<li><p>PyTorch中的<code>weight_decay</code>参数说明</p>
</li>
</ul>
<blockquote>
<p>weight_decay (float, optional): weight decay (L2 penalty) (default: 0)</p>
</blockquote>
<ul>
<li><p>我之前的实现代码:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># zero the parameter gradients</span><br><span class="line">optimizer.zero_grad()</span><br><span class="line"># forward</span><br><span class="line">outputs = model(inputs)</span><br><span class="line"># _, preds = torch.max(outputs.data, 1)</span><br><span class="line">loss = loss_criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line"># L1 regularization</span><br><span class="line">l1_loss = 0</span><br><span class="line">for w in model.parameters():</span><br><span class="line">    l1_loss += torch.sum(torch.abs(w))</span><br><span class="line">loss += l1_rate * l1_loss</span><br><span class="line"></span><br><span class="line"># backward + optimize only if in training phase</span><br><span class="line">if phase == &apos;train&apos;:</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<ul>
<li>其中 <code># L1 regularization</code>后面是添加的L1 正则化</li>
</ul>
</li>
<li><p>就整体而言，对比加入正则化和未加入正则化的模型，训练输出的loss和Accuracy信息，我们可以发现，加入正则化后，loss下降的速度会变慢，准确率Accuracy的上升速度会变慢，并且未加入正则化模型的loss和Accuracy的浮动比较大（或者方差比较大），而加入正则化的模型训练loss和Accuracy，表现的比较平滑。并且随着正则化的权重lambda越大，表现的更加平滑。这其实就是正则化的对模型的惩罚作用，通过正则化可以使得模型表现的更加平滑，即通过正则化可以有效解决模型过拟合的问题。</p>
</li>
</ul>
<h4 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h4><ul>
<li>提高模型的泛化能力最好的办法是, <strong>使用更多的训练数据进行训练</strong></li>
<li>创造一些假数据添加到训练集中</li>
<li>实例: <ul>
<li>AlexNet中使用对图片旋转等方式生成新的图片作为样本加入训练, 误差能降低1%</li>
</ul>
</li>
</ul>
<h4 id="提前终止训练"><a href="#提前终止训练" class="headerlink" title="提前终止训练"></a>提前终止训练</h4><ul>
<li>当发现数据在验证集上的损失趋于收敛甚至开始增加时,停止训练</li>
<li>即使模型在验证集上的损失还在减小</li>
</ul>
<h4 id="参数绑定与参数共享"><a href="#参数绑定与参数共享" class="headerlink" title="参数绑定与参数共享"></a>参数绑定与参数共享</h4><p><em>Soft Weight Sharing</em></p>
<ul>
<li>类似于CNN中卷积层的权重共享方法</li>
<li>RNN中也有权重共享, 整条时间链上的参数共享</li>
</ul>
<h4 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h4><ul>
<li>其实bagging的方法是可以起到正则化的作用,因为正则化就是要减少泛化误差,而bagging的方法可以组合多个模型起到减少泛化误差的作用</li>
<li>在深度学习中同样可以使用此方法,但是其会增加计算和存储的成本<ul>
<li>这一点在Kaggle比赛中有用过,的确有很大提高</li>
</ul>
</li>
</ul>
<h4 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h4><ul>
<li>在Google Inception V2中所采用,是一种非常有用的正则化方法,可以让大型的卷积网络训练速度加快很多倍,同事收敛后分类的准确率也可以大幅度的提高.</li>
<li>N在训练某层时,会对每一个mini-batch数据进行标准化(normalization)处理,使输出规范到N(0,1)的正太分布,减少了Internal convariate shift(内部神经元分布的改变),传统的深度神经网络在训练是,每一层的输入的分布都在改变,因此训练困难,只能选择用一个很小的学习速率,但是每一层用了BN后,可以有效的解决这个问题,学习速率可以增大很多倍</li>
<li>更多信息参考: <a href="/Notes/DL/DL%E2%80%94%E2%80%94BN-LN-IN-GN-LRN-WN.html">DL——BN-LN-IN-GN-LRN-WN</a></li>
</ul>
<h4 id="辅助分类节点"><a href="#辅助分类节点" class="headerlink" title="辅助分类节点"></a>辅助分类节点</h4><p><em>(auxiliary classifiers)</em></p>
<ul>
<li>在Google Inception V1中,采用了辅助分类节点的策略,即将<strong>中间某一层的输出用作分类,并按一个较小的权重加到最终的分类结果中</strong>,这样相当于做了模型的融合,同时给网络增加了反向传播的梯度信号,提供了额外的正则化的思想.</li>
</ul>
<h4 id="尝试不同神经网络架构"><a href="#尝试不同神经网络架构" class="headerlink" title="尝试不同神经网络架构"></a>尝试不同神经网络架构</h4><ul>
<li>尝试替换以下方面:<ul>
<li>激活函数</li>
<li>层数</li>
<li>权重?</li>
<li>层的参数?</li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/DL/DL——重参数化技巧.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/DL/DL——重参数化技巧.html" itemprop="url">DL——重参数化技巧</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <!-- <script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"  type="text/javascript"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<ul>
<li>参考链接：<ul>
<li><a href="https://kexue.fm/archives/6705" target="_blank" rel="noopener">漫谈重参数：从正态分布到Gumbel Softmax</a>  </li>
<li><a href="https://zhuanlan.zhihu.com/p/561328468" target="_blank" rel="noopener">重参数化技巧（Gumbel-Softmax）</a>  </li>
<li><a href="https://zhuanlan.zhihu.com/p/633431594" target="_blank" rel="noopener">通俗易懂地理解Gumbel Softmax</a>  </li>
</ul>
</li>
</ul>
<hr>
<h3 id="重参数化解决的问题"><a href="#重参数化解决的问题" class="headerlink" title="重参数化解决的问题"></a>重参数化解决的问题</h3><ul>
<li><strong>问题</strong>：假设用NN建模一个分布，比如正太分布可以表达为\(\mathcal{N}(\mu_\theta,\sigma_\theta)\)，此时如果直接从NN建模的分布中采样，由于<strong>采样动作</strong>是离散的，那么这个采样结果不包含NN分布的梯度信息的，NN反向传播时无法传播回去，也无法实现对参数 \(\theta\) 的更新</li>
<li><strong>重参数化技巧</strong>：通过一些技巧设计采样方式，使得采样过程可导，让采样结果包含NN分布的梯度信息（即实现<strong>既可按照NN分布采样</strong>，<strong>又可回传梯度信息</strong>）</li>
</ul>
<hr>
<h3 id="重参数化的基本思想"><a href="#重参数化的基本思想" class="headerlink" title="重参数化的基本思想"></a>重参数化的基本思想</h3><ul>
<li>不能梯度回传的本质原因是因为采样过程是一种选择动作，这种选择动作本身没有梯度信息，把采样过程挪到计算图之外</li>
<li>用形式来表示，将\(z \sim f(\theta)\)构建为形如\(z = g(\theta, \epsilon), \epsilon \sim p\)的形式（其中p是与参数无关的某个分布，比如高斯分布）</li>
</ul>
<hr>
<h3 id="连续变量分布采样的重参数化"><a href="#连续变量分布采样的重参数化" class="headerlink" title="连续变量分布采样的重参数化"></a>连续变量分布采样的重参数化</h3><ul>
<li>以正太分布为例，原始NN分布采样形式：<br>  $$ z \sim \mathcal{N}(\mu_\theta,\sigma_\theta) $$</li>
<li>重参数技巧采样：<br>  $$<br>  \begin{align}<br>  \epsilon \sim \mathcal{N}(0,1) \\<br>  z = \mu_\theta + \sigma_\theta \cdot \epsilon<br>  \end{align}<br>  $$</li>
</ul>
<hr>
<h3 id="离散变量分布采样的重参数化"><a href="#离散变量分布采样的重参数化" class="headerlink" title="离散变量分布采样的重参数化"></a>离散变量分布采样的重参数化</h3><p><em>以下内容主要参考自<a href="https://zhuanlan.zhihu.com/p/561328468" target="_blank" rel="noopener">重参数化技巧（Gumbel-Softmax）</a>以及其中的回复讨论</em></p>
<h4 id="原版-softmax（原始问题）："><a href="#原版-softmax（原始问题）：" class="headerlink" title="原版 softmax（原始问题）："></a>原版 softmax（原始问题）：</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">logits = model(x)</span><br><span class="line">probs = softmax(logits)</span><br><span class="line">r = torch.multinomial(probs, num_samples)</span><br></pre></td></tr></table></figure>

<ul>
<li>采到的 r 都是整数 ID，后面可以用 r 去查 embedding table。缺点是采样这一步把计算图弄断了。</li>
</ul>
<h4 id="Gumbel-Max-Trick"><a href="#Gumbel-Max-Trick" class="headerlink" title="Gumbel-Max Trick:"></a>Gumbel-Max Trick:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def sample_gumbel(shape, eps=1e-20, tens_type=torch.FloatTensor):</span><br><span class="line">    &quot;&quot;&quot;Sample from Gumbel(0, 1)&quot;&quot;&quot;</span><br><span class="line">    U = Variable(tens_type(*shape).uniform_(), requires_grad=False)</span><br><span class="line">    return -torch.log(-torch.log(U + eps) + eps)</span><br><span class="line"></span><br><span class="line">logits = model(x)</span><br><span class="line">g = sample_gumbel(logits.size())</span><br><span class="line">r = torch.argmax(logits + g)</span><br></pre></td></tr></table></figure>

<ul>
<li>采到的 r 都是整数 ID，后面可以用 r 去查 embedding table，计算图连起来了，但 argmax 仍不可导</li>
<li><strong>为什么一定要用sample_gumbel分布而不是其他分布？</strong><ul>
<li>因为只有使用gumbel分布采样才能保证与原始softmax后的多项式分布采样完全等价，即 <strong>argmax(logits + Gumbel随机变量)与多项式分布采样严格等价</strong>，相关证明见：<a href="https://kexue.fm/archives/6705" target="_blank" rel="noopener">漫谈重参数：从正态分布到Gumbel Softmax</a>  </li>
</ul>
</li>
<li>Gumbel分布的具体定义是什么？<ul>
<li>一般Gumbel分布的PDF和CDF：<br>$$<br>\begin{align}<br>\text{PDF}: \quad f(x;\mu,\beta) = e^{-(z+e^{-z})},\quad z=\frac{x-\mu}{\beta} \\<br>\text{CDF}: \quad F(x;\mu,\beta) = e^{-e^{-z}}, \quad z=\frac{x-\mu}{\beta}<br>\end{align}<br>$$<ul>
<li>\(\mu\)是位置参数（location parameter）</li>
<li>\(\beta\)是尺度参数（scale parameter）</li>
</ul>
</li>
<li>标准Gumbel分布中，\(\mu=0,\ \beta=1\)，此时有\(z=x\)<br>$$<br>\begin{align}<br>\text{PDF}: \quad f(x;\mu,\beta) = e^{-(x+e^{-x})} \\<br>\text{CDF}: \quad F(x;\mu,\beta) = e^{-e^{-x}}<br>\end{align}<br>$$</li>
</ul>
</li>
<li>在这个场景中，我们使用标准Gumbel分布即可</li>
<li>采样标准Gumbel分布时，可以直接使用<strong>逆变换采样（Inverse Transform Sampling）</strong>：<ul>
<li>先按照均匀分布采样：\(u = \mathcal{U}(0,1)\)</li>
<li>对Gumbel分布原始CDF取逆Gumbel分布采样结果：\(z = -ln(-ln(u))\)</li>
</ul>
</li>
</ul>
<h4 id="Gumbel-Softmax-Trick"><a href="#Gumbel-Softmax-Trick" class="headerlink" title="Gumbel-Softmax Trick:"></a>Gumbel-Softmax Trick:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">logits = model(x)</span><br><span class="line">g = sample_gumbel(logits.size())</span><br><span class="line">r = F.softmax(logits + g)</span><br></pre></td></tr></table></figure>

<ul>
<li>采到的 r 都是概率分布，后面可以用 r 把 embedding table 里的各个条目加权平均混合起来，假装是一个单词拿去用。虽然计算图可导了，但是训练和推断不一致！训练时模型见到的都是各个 word embedding 的混合，而非独立的 word embedding！推断时则使用的是独立的 word embedding！</li>
</ul>
<h4 id="Gumbel-Softmax-Trick-Straight-Though-Estimator"><a href="#Gumbel-Softmax-Trick-Straight-Though-Estimator" class="headerlink" title="Gumbel-Softmax Trick + Straight-Though Estimator:"></a>Gumbel-Softmax Trick + Straight-Though Estimator:</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">logits = model(x)</span><br><span class="line">g = sample_gumbel(logits.size())</span><br><span class="line">r = F.softmax(logits + g)</span><br><span class="line">r_hard = torch.argmax(r)</span><br><span class="line">r = (r_hard - r).detach() + r</span><br></pre></td></tr></table></figure>

<ul>
<li>采到的 r 都是整数 ID，后面可以用 r 去查 embedding table</li>
<li>前向传播使用 r_hard 获得独立的单词，反向传播使用 r（即 softmax 的结果）的梯度。一切都很完美。</li>
<li>Straight-Through Estimator 的意思是说，如果你遇到某一层不可导，你就当它的梯度是 identity，直接把梯度漏下去，即假定当前层的梯度为1</li>
<li>实际上此时正向传播和反向传播面对的公式也不一样<ul>
<li>正向传播时得到的是<code>r_hard</code></li>
<li>反向传播时，由于<code>(r_hard - r).detach()</code>使得梯度为0，所以回传的实际是<code>r</code>的反向梯度</li>
</ul>
</li>
</ul>
<hr>
<h3 id="argmax动作的梯度回传"><a href="#argmax动作的梯度回传" class="headerlink" title="argmax动作的梯度回传"></a>argmax动作的梯度回传</h3><ul>
<li>argmax操作的形式：<br>  $$<br>  \begin{align}<br>  i^* &amp;= \mathop{\arg\max}_i (\vec{x}) \\<br>  \text{where} \quad \vec{x}=&amp;(x_1, x_2, \cdots, x_n), \quad x_i = f(\theta)_i<br>  \end{align}<br>  $$<ul>
<li>注：以上argmax的写法不严谨，严谨的是\(i^* = \mathop{argmax}_i x_i, \ x_i \in \vec{x}\)</li>
</ul>
</li>
<li>近似形式：<br>  $$<br>  \begin{equation}<br>  \mathop{\arg\max}_i (\vec{x}) \approx \sum_{i=1}^n i\times \text{softmax}(\vec{x})_i<br>  \end{equation}<br>  $$</li>
<li>argmax本质也可以看做一种离散采样，只是没有随机性，该采样选择使得目标值最大的离散变量</li>
<li>详情见：<a href="https://kexue.fm/archives/6620" target="_blank" rel="noopener">函数光滑化杂谈：不可导函数的可导逼近</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/PyTorch/PyTorch——backward函数详细解析.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/PyTorch/PyTorch——backward函数详细解析.html" itemprop="url">PyTorch——backward函数详细解析</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><em>本文主要介绍PyTorch中backward函数和grad的各种用法</em></p>
<!-- <script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"  type="text/javascript"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


<hr>
<h3 id="梯度的定义"><a href="#梯度的定义" class="headerlink" title="梯度的定义"></a>梯度的定义</h3><ul>
<li>\(y\)对\(x\)的梯度可以理解为: <strong>当 \(x\) 增加1的时候, \(y\) 值的增加量</strong></li>
<li>如果\(x\)是矢量(矩阵或者向量等),那么计算时也需要看成是多个标量的组合来计算,算出来的值表示的也是 \(x\) 当前维度的值增加1的时候, \(y\) 值的增加量</li>
</ul>
<hr>
<h3 id="backward基础用法"><a href="#backward基础用法" class="headerlink" title="backward基础用法"></a>backward基础用法</h3><ul>
<li>tensorflow是先建立好图，在前向过程中可以选择执行图的某个部分(每次前向可以执行图的不同部分，前提是，图里必须包含了所有可能情况)</li>
<li>pytorch是每次前向过程都会重新建立一个图，反向(backward)的时候会释放，每次的图可以不一样, 所以在Pytorch中可以随时使用<code>if</code>, <code>while</code>等语句 <ul>
<li>tensorflow中使用<code>if</code>, <code>while</code>就得在传入数据前(构建图时)告诉图需要构建哪些逻辑,然后才能传入数据运行</li>
<li>PyTorch中由于不用在传入数据前先定义图(图和数据一起到达,图构建的同时开始计算数据?)</li>
</ul>
</li>
</ul>
<h4 id="计算标量对标量的梯度"><a href="#计算标量对标量的梯度" class="headerlink" title="计算标量对标量的梯度"></a>计算标量对标量的梯度</h4><ul>
<li><p>结构图如下所示</p>
<img src="/Notes/PyTorch/PyTorch——backward函数详细解析/backward_tree_scalar2scalar.jpg"></li>
<li><p>上面图的代码构建如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"></span><br><span class="line">w1 = Variable(torch.Tensor([2]),requires_grad=True)</span><br><span class="line">w2 = Variable(torch.Tensor([3]),requires_grad=True)</span><br><span class="line">w3 = Variable(torch.Tensor([5]),requires_grad=True)</span><br><span class="line">x = w1 + w2</span><br><span class="line">y = w2*w3</span><br><span class="line">z = x+y</span><br><span class="line">z.backward()</span><br><span class="line">print(w1.grad)</span><br><span class="line">print(w2.grad)</span><br><span class="line">print(w3.grad)</span><br><span class="line">print(x.grad)</span><br><span class="line">print(y.grad)</span><br><span class="line"></span><br><span class="line"># output:</span><br><span class="line">tensor([1.])</span><br><span class="line">tensor([6.])</span><br><span class="line">tensor([3.])</span><br><span class="line">None</span><br><span class="line">None</span><br></pre></td></tr></table></figure>

<ul>
<li>从图中的推导可知,梯度符合预期</li>
<li>\(x, y\)不是叶节点,没有梯度存储下来,注意可以理解为梯度计算了,只是没有存储下来,PyTorch中梯度是一层层计算的</li>
</ul>
</li>
</ul>
<h4 id="计算标量对矢量的梯度"><a href="#计算标量对矢量的梯度" class="headerlink" title="计算标量对矢量的梯度"></a>计算标量对矢量的梯度</h4><ul>
<li><p>修改上面的构建为</p>
<ul>
<li>增加变量 \(s = z.mean\),然后直接求取\(s\)的梯度</li>
</ul>
</li>
<li><p>结构图如下:</p>
<img src="/Notes/PyTorch/PyTorch——backward函数详细解析/backward_tree_scalar2vector.jpg"></li>
<li><p>代码如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"></span><br><span class="line">w1 = Variable(torch.ones(2,2)*2,requires_grad=True)</span><br><span class="line">w2 = Variable(torch.ones(2,2)*3,requires_grad=True)</span><br><span class="line">w3 = Variable(torch.ones(2,2)*5,requires_grad=True)</span><br><span class="line">x = w1 + w2</span><br><span class="line">y = w2*w3</span><br><span class="line">z = x+y</span><br><span class="line"># z.backward()</span><br><span class="line">s = z.mean()</span><br><span class="line">s.backward()</span><br><span class="line">print(w1.grad)</span><br><span class="line">print(w2.grad)</span><br><span class="line">print(w3.grad)</span><br><span class="line">print(x.grad)</span><br><span class="line">print(y.grad)</span><br><span class="line"># output:</span><br><span class="line">tensor([[0.2500, 0.2500],</span><br><span class="line">        [0.2500, 0.2500]])</span><br><span class="line">tensor([[1.5000, 1.5000],</span><br><span class="line">        [1.5000, 1.5000]])</span><br><span class="line">tensor([[0.7500, 0.7500],</span><br><span class="line">        [0.7500, 0.7500]])</span><br><span class="line">None</span><br><span class="line">None</span><br></pre></td></tr></table></figure>

<ul>
<li>显然推导结果符合代码输出预期</li>
<li>梯度的维度与原始自变量的维度相同,每个元素都有自己对应的梯度,表示<strong>当当前元素增加1的时候, 因变量值的增加量</strong></li>
</ul>
</li>
</ul>
<h4 id="计算矢量对矢量的梯度"><a href="#计算矢量对矢量的梯度" class="headerlink" title="计算矢量对矢量的梯度"></a>计算矢量对矢量的梯度</h4><ul>
<li><p>还以上面的结构图为例</p>
</li>
<li><p>直接求中间节点 \(z\) 关于自变量的梯度</p>
</li>
<li><p>代码如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">from torch.autograd import Variable</span><br><span class="line"></span><br><span class="line">w1 = Variable(torch.ones(2,2)*2, requires_grad=True)</span><br><span class="line">w2 = Variable(torch.ones(2,2)*3, requires_grad=True)</span><br><span class="line">w3 = Variable(torch.ones(2,2)*5, requires_grad=True)</span><br><span class="line">x = w1 + w2</span><br><span class="line">y = w2*w3</span><br><span class="line">z = x+y</span><br><span class="line">z_w1_grad = torch.autograd.grad(outputs=z, inputs=w1, grad_outputs=torch.ones_like(z))</span><br><span class="line">print(z_w1_grad)</span><br></pre></td></tr></table></figure>

<ul>
<li>在因变量是矢量时,<code>grad_outputs</code>参数不能为空,标量时可以为空(<code>grad_outputs</code>为空时和<code>grad_outputs</code>维度为1时等价)</li>
<li><code>grad_outputs</code>的维度必须和<code>outputs</code>参数的维度兼容</li>
</ul>
</li>
</ul>
<h4 id="关于autograd-grad函数"><a href="#关于autograd-grad函数" class="headerlink" title="关于autograd.grad函数"></a>关于autograd.grad函数</h4><ul>
<li>参考博客: <a href="https://blog.csdn.net/qq_36556893/article/details/91982925" target="_blank" rel="noopener">https://blog.csdn.net/qq_36556893/article/details/91982925</a></li>
</ul>
<h5 id="grad-outputs参数详解"><a href="#grad-outputs参数详解" class="headerlink" title="grad_outputs参数详解"></a><code>grad_outputs</code>参数详解</h5><ul>
<li>在因变量是矢量时,<code>grad_outputs</code>参数不能为空,标量时可以为空(<code>grad_outputs</code>为空时和<code>grad_outputs</code>维度为1时等价)</li>
<li><code>grad_outputs</code>的维度必须和<code>outputs</code>参数的维度兼容<br>[待更新]</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/PyTorch/PyTorch——CrossEntopyLoss和NLLLoss的区别.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/PyTorch/PyTorch——CrossEntopyLoss和NLLLoss的区别.html" itemprop="url">PyTorch——CrossEntopyLoss和NLLLoss的区别</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <!-- <script src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"  type="text/javascript"></script> -->
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


<hr>
<h3 id="NLLLoss"><a href="#NLLLoss" class="headerlink" title="NLLLoss"></a>NLLLoss</h3><ul>
<li><p>使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.NLLLoss()</span><br></pre></td></tr></table></figure>
</li>
<li><p>具体操作</p>
<ul>
<li>返回负对数似然损失(The negative log likelihood loss)</li>
<li>虽然命名是负对数自然损失, 但是实际上本函数不含有<code>log</code>操作,本函数假设<code>log</code>操作在输入前已经完成了</li>
</ul>
</li>
<li><p>常用于分类问题的损失函数</p>
</li>
<li><p>一般适用于网络最后一层为<code>log_softmax</code>的时候</p>
</li>
</ul>
<h4 id="计算公式"><a href="#计算公式" class="headerlink" title="计算公式"></a>计算公式</h4><ul>
<li>单个样本的计算公式:<ul>
<li>普通样本计算公式:<br>$$loss(x, class) = -x[class]$$</li>
<li>带有权重的单个样本计算公式:<br>$$loss(x, class) = -weights[class] * x[class]$$</li>
<li>因为多类别分类中,类别中只有一个维度是1, 其他维度都是0, 所以在计算时只考虑为1的维度就行, 为0的维度与当前类别值相乘为0<ul>
<li>(在这里我们存储的不是向量,而是该为1的维度的索引,所以使用-x[class]即可直接取出该样本对应的对数似然损失,其中,取对数的操作在输入前已经完成了) </li>
</ul>
</li>
</ul>
</li>
<li>批量样本的计算公式:<ul>
<li><code>size_average=True</code>(default):<br>$$all\_loss = \frac{1}{mini\_batch\_size}\sum_i loss(x_i, class_i)$$</li>
<li><code>size_average=False</code>:<br>$$all\_loss = \sum_i loss(x_i, class_i)$$</li>
</ul>
</li>
</ul>
<hr>
<h3 id="CrossEntropyLoss"><a href="#CrossEntropyLoss" class="headerlink" title="CrossEntropyLoss"></a>CrossEntropyLoss</h3><ul>
<li><p>使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>
</li>
<li><p>具体操作</p>
<ul>
<li>等价于 <code>log_softmax</code> + <code>torch.nn.NLLLoss()</code></li>
<li>先对网络输出做对数似然, 然后再</li>
</ul>
</li>
<li><p>softmax的定义<br>$$softmax(x_{i}) = \frac{e^{x_{i}}}{\sum_{j=1}x_{j}}$$</p>
</li>
<li><p>log_softmax的定义<br>$$log(softmax(x_{i}))$$</p>
<ul>
<li>注意: 这里的<code>log</code>是以<code>e</code>为底的对数</li>
</ul>
</li>
</ul>
<h4 id="为什么是这种实现方式"><a href="#为什么是这种实现方式" class="headerlink" title="为什么是这种实现方式?"></a>为什么是这种实现方式?</h4><ul>
<li>为什么是<code>log_softmax</code> + <code>torch.nn.NLLLoss()</code>的方式而不是普通的计算方式<ul>
<li>普通的计算方式是直接对每个概率求出log值, 然后相加, 本质上是一样的</li>
<li><code>CrossEntropyLoss</code>中多了个softmax是为了保证输入都是概率值</li>
</ul>
</li>
<li><code>log(softmax(x))</code>的优化<ul>
<li>实际上使用的是<code>log_softmax(x)</code></li>
<li><code>log_softmax(x)</code>的运算速度比单独计算<code>softmax</code> + <code>log</code>的速度快</li>
<li>同时二者的运算结果相同</li>
<li>文档中没有提到, 但是一种可能的优化方法是<br>$$<br>\begin{align}<br>log_sofmax(x) &amp;= log \frac{e^{x_{i}}}{\sum_{j=1}x_{j}} \\<br>&amp;= log e^{x_i} - log \sum_{j=1}x_{j} \\<br>&amp;= x_i - log \sum_{j=1}x_{j}<br>\end{align}<br>$$</li>
<li>上面的式子中,只需要计算一次 \(log \sum_{j=1}x_{j}\)即可(且不同维度可重用该值), 其他的都是加减法运算</li>
</ul>
</li>
</ul>
<h3 id="相关损失函数-BCELoss"><a href="#相关损失函数-BCELoss" class="headerlink" title="相关损失函数 BCELoss"></a>相关损失函数 BCELoss</h3><ul>
<li><p>使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.BCELoss()</span><br></pre></td></tr></table></figure>
</li>
<li><p>具体操作</p>
<ul>
<li>就是实现了书上定义的二分类交叉熵定义</li>
</ul>
</li>
</ul>
<h4 id="计算公式-1"><a href="#计算公式-1" class="headerlink" title="计算公式:"></a>计算公式:</h4><ul>
<li>单个样本的计算公式:<ul>
<li>普通样本计算公式:<br>$$ loss(o,t)=-\frac{1}{n}\sum_i(t[i]\log(o[i])+(1-t[i])\log(1-o[i])) $$</li>
<li>带有权重的单个样本计算公式:<br>$$ loss(o,t)=-\frac{1}{n}\sum_iweights[i]\ (t[i]log(o[i])+(1-t[i])*\log(1-o[i])) $$</li>
<li>因为多类别分类中,类别中只有一个维度是1, 其他维度都是0, 所以在计算时只考虑为1的维度就行, 为0的维度与当前类别值相乘为0<ul>
<li>(在这里我们存储的不是向量,而是该为1的维度的索引,所以使用-x[class]即可直接取出该样本对应的对数似然损失,其中,取对数的操作在输入前已经完成了) </li>
</ul>
</li>
</ul>
</li>
<li>批量样本的计算公式:<ul>
<li><code>size_average=True</code>(default):<br>$$all\_loss = \frac{1}{mini\_batch\_size}\sum_i loss(o_i, t_i)$$</li>
<li><code>size_average=False</code>:<br>$$all\_loss = \sum_i loss(o_i, t_i)$$</li>
</ul>
</li>
</ul>
<h4 id="BCELoss-vs-CrossEntropyLoss"><a href="#BCELoss-vs-CrossEntropyLoss" class="headerlink" title="BCELoss vs CrossEntropyLoss"></a>BCELoss vs CrossEntropyLoss</h4><ul>
<li><code>BCELoss</code>对应的网络只有一个输出值</li>
<li><code>CrossEntropyLoss</code>对应的网络有两个输出值</li>
<li>可以证明, 二分类时<code>BCELoss</code> 与 <code>CrossEntropyLoss</code>等价<ul>
<li>证明时, 将每个<code>CrossEntropyLoss</code>的计算公式中的 <code>softmax</code> 函数分子分母同时除以<code>shift</code>, 即可得到为下面的定义, 进一步可得到<code>BCELoss</code>的计算公式<br>$$f_i(x) = \frac{e^{(x_i - shift)}} { \sum^j e^{(x_j - shift)}},shift = max (x_i)$$</li>
</ul>
</li>
</ul>
<h3 id="相关损失函数-MultiLabelMarginLoss"><a href="#相关损失函数-MultiLabelMarginLoss" class="headerlink" title="相关损失函数 MultiLabelMarginLoss"></a>相关损失函数 MultiLabelMarginLoss</h3><ul>
<li><p>使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MultiLabelMarginLoss()</span><br></pre></td></tr></table></figure>
</li>
<li><p>用于多标签分类的损失函数</p>
</li>
</ul>
<hr>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li>一般来说直接使用<code>CrossEntropyLoss</code>即可<ul>
<li>二分类时还可以使用<code>nn.BCELoss</code></li>
<li>二分类时使用<code>nn.BCELoss</code>的话,输入的<code>input</code>和<code>target</code>维度都为<code>n * 1</code>的维度</li>
<li>二分类时使用<code>CrossEntropyLoss</code>则输入的<code>input</code>为<code>n * 2</code>的维度</li>
</ul>
</li>
<li>如果使用<code>NLLLoss</code>则一定记得在输出层最后加一层<code>log_softmax</code>层</li>
<li>注意,<code>log</code>指的是以<code>e</code>为底的对数函数,而不是以<code>10</code>为底的<ul>
<li>Mac自带的计算器中<code>log</code>是以<code>10</code>为底的,<code>ln</code>才是以<code>e</code>为底的</li>
</ul>
</li>
<li></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://JoeZJH.github.io/Notes/PyTorch/PyTorch——使用问题记录.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Joe Zhou">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/jiahong-head.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiahong的个人博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Notes/PyTorch/PyTorch——使用问题记录.html" itemprop="url">PyTorch——使用问题记录</a></h1>
        

        <div class="post-meta">
          

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="PyTorch和torchvision版本不兼容"><a href="#PyTorch和torchvision版本不兼容" class="headerlink" title="PyTorch和torchvision版本不兼容"></a>PyTorch和torchvision版本不兼容</h3><ul>
<li><p>问题描述：<br><code>RuntimeError: Couldn&#39;t load custom C++ ops. This can happen if your PyTorch and torchvision versions are incompatible, or if you had errors while compiling torchvision from source. For further information on the compatible versions, check https://github.com/pytorch/vision#installation for the compatibility matrix. Please check your PyTorch version with torch.version and your torchvision version with torchvision.version and verify if they are compatible, and if not please reinstall torchvision so that it matches your PyTorch install. </code></p>
</li>
<li><p>解决方案：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch torchvision --upgrade</span><br></pre></td></tr></table></figure>

</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/23/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><span class="page-number current">24</span><a class="page-number" href="/page/25/">25</a><span class="space">&hellip;</span><a class="page-number" href="/page/29/">29</a><a class="extend next" rel="next" href="/page/25/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/jiahong-head.png" alt="Joe Zhou">
            
              <p class="site-author-name" itemprop="name">Joe Zhou</p>
              <p class="site-description motion-element" itemprop="description">本博客主要用于记录个人学习笔记</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">284</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">48</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/JoeZJH" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="JoeZJiahong@Foxmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Joe Zhou</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
